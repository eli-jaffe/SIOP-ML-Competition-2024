{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d290d4723f514358ad402b2c0fa0e33d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97f1ad77a933426f9eb4f8265514393d",
              "IPY_MODEL_454d4450faf4466b9fd6b21b2fb4c5f9",
              "IPY_MODEL_20ad322c048d4e2f87a5333e52a431dc"
            ],
            "layout": "IPY_MODEL_e151d66df18c448ab1b64958abf99cd3"
          }
        },
        "97f1ad77a933426f9eb4f8265514393d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed9dc324e9244c6fa9e3ca8c651d5583",
            "placeholder": "​",
            "style": "IPY_MODEL_490498a144ae4117bee9bcc668d851e7",
            "value": ""
          }
        },
        "454d4450faf4466b9fd6b21b2fb4c5f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f568d46c6d7433eb20f01804ee9fd07",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c14141967c644e5bdb75002c12a173e",
            "value": 0
          }
        },
        "20ad322c048d4e2f87a5333e52a431dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fca159acd944907913b29bd226282c7",
            "placeholder": "​",
            "style": "IPY_MODEL_058beab893a44f44b5c271dd9b30704b",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "e151d66df18c448ab1b64958abf99cd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed9dc324e9244c6fa9e3ca8c651d5583": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "490498a144ae4117bee9bcc668d851e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f568d46c6d7433eb20f01804ee9fd07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7c14141967c644e5bdb75002c12a173e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1fca159acd944907913b29bd226282c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "058beab893a44f44b5c271dd9b30704b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fa36aa363d34a2f9e81c958e12f7036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbf11a6fd4d541119856eab1b72fd1ce",
              "IPY_MODEL_3b0abf10257642d0b524e8ef1fd80abe",
              "IPY_MODEL_4ddd0627d2ec46a3b4079f88ce3b0998"
            ],
            "layout": "IPY_MODEL_65b8d5c7985d475f8e62e64162b7d941"
          }
        },
        "cbf11a6fd4d541119856eab1b72fd1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddabb48dc0014d41b46eab8b4e5313ee",
            "placeholder": "​",
            "style": "IPY_MODEL_b3634bf9f2744c429387fdfdc9e26035",
            "value": "config.json: 100%"
          }
        },
        "3b0abf10257642d0b524e8ef1fd80abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b76d8776c6a3425f82b84f7f4bbf66a6",
            "max": 720,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_729054f23c1c4789a6dd661026154296",
            "value": 720
          }
        },
        "4ddd0627d2ec46a3b4079f88ce3b0998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61d7521d28404fbd88b419cc68308fda",
            "placeholder": "​",
            "style": "IPY_MODEL_1a7111a2a1904459a26665aa896f85b2",
            "value": " 720/720 [00:00&lt;00:00, 51.3kB/s]"
          }
        },
        "65b8d5c7985d475f8e62e64162b7d941": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddabb48dc0014d41b46eab8b4e5313ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3634bf9f2744c429387fdfdc9e26035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b76d8776c6a3425f82b84f7f4bbf66a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "729054f23c1c4789a6dd661026154296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "61d7521d28404fbd88b419cc68308fda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a7111a2a1904459a26665aa896f85b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6c9ecdd1bc94bc9b0a8d89b1ebdf79b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c9c49144a0a4f5198e30eb799e5e7c4",
              "IPY_MODEL_d267a1e56071491dbcd819539fb297fc",
              "IPY_MODEL_5f97fa43b53b42949455ad182dbfa11a"
            ],
            "layout": "IPY_MODEL_7b1cf5db95044abea5515bd30569a6db"
          }
        },
        "4c9c49144a0a4f5198e30eb799e5e7c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd675ac722d5402aa10be2c13706284d",
            "placeholder": "​",
            "style": "IPY_MODEL_0d9721aa908840498d42ac64bd47a441",
            "value": "Loading experts: 100%"
          }
        },
        "d267a1e56071491dbcd819539fb297fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d29ce4e7877446018b3501f9689090d1",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6a24f2f66694ad381b6dcb4156ab011",
            "value": 32
          }
        },
        "5f97fa43b53b42949455ad182dbfa11a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2b0b8c62e9f49c4aeccce35a27bdda4",
            "placeholder": "​",
            "style": "IPY_MODEL_79ac76eb473a48a6a0a2c20d2fde6af6",
            "value": " 32/32 [00:11&lt;00:00,  2.75it/s]"
          }
        },
        "7b1cf5db95044abea5515bd30569a6db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd675ac722d5402aa10be2c13706284d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d9721aa908840498d42ac64bd47a441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d29ce4e7877446018b3501f9689090d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6a24f2f66694ad381b6dcb4156ab011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2b0b8c62e9f49c4aeccce35a27bdda4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79ac76eb473a48a6a0a2c20d2fde6af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccded232b2404ee7875465fbb68d40da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33d67af9bb2a4acb8ef3fad993f46058",
              "IPY_MODEL_dd45259912864603898bb2a9844205b3",
              "IPY_MODEL_b75d333cfd844ebfb4a53564e735c65c"
            ],
            "layout": "IPY_MODEL_e6f3d732c0f64c4c99319455d0698dc6"
          }
        },
        "33d67af9bb2a4acb8ef3fad993f46058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35c557f403344a368e19fb1644e38330",
            "placeholder": "​",
            "style": "IPY_MODEL_791ca59c26ec4843a6f8cf5069972fb0",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "dd45259912864603898bb2a9844205b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3df9e9c2c20948e2a89ededf04e233d5",
            "max": 1460,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_052c5e6ef6ab430f80392ffa7b0f7182",
            "value": 1460
          }
        },
        "b75d333cfd844ebfb4a53564e735c65c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fdd6b275a6e48f38f2ab924b96d402b",
            "placeholder": "​",
            "style": "IPY_MODEL_f1750646a1544ede9e248652391e8bde",
            "value": " 1.46k/1.46k [00:00&lt;00:00, 98.3kB/s]"
          }
        },
        "e6f3d732c0f64c4c99319455d0698dc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35c557f403344a368e19fb1644e38330": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "791ca59c26ec4843a6f8cf5069972fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3df9e9c2c20948e2a89ededf04e233d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "052c5e6ef6ab430f80392ffa7b0f7182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5fdd6b275a6e48f38f2ab924b96d402b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1750646a1544ede9e248652391e8bde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96c591940ba944ec8d5263b2e88669b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b061778c3204d31a20104b83b894cd2",
              "IPY_MODEL_1354433a13ad46b295fef26fddeb5871",
              "IPY_MODEL_e4ff8d49fce34773b829be1e43931c09"
            ],
            "layout": "IPY_MODEL_d321ccd5170546558c99ebcab1e0ae12"
          }
        },
        "5b061778c3204d31a20104b83b894cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bcfd26cfb014a1c8e2a302978269600",
            "placeholder": "​",
            "style": "IPY_MODEL_1cd91bf2e9c746edb7517c257af1d038",
            "value": "tokenizer.model: 100%"
          }
        },
        "1354433a13ad46b295fef26fddeb5871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd133078749241e89d16ebcf843c8f8e",
            "max": 493443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7259a63d8ac6457a8fb1c94985c21ad3",
            "value": 493443
          }
        },
        "e4ff8d49fce34773b829be1e43931c09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_218eee7ce90f4bdabae26d5f22c6411c",
            "placeholder": "​",
            "style": "IPY_MODEL_e8c1e0449ad64c8392f2d09da1f59813",
            "value": " 493k/493k [00:00&lt;00:00, 5.55MB/s]"
          }
        },
        "d321ccd5170546558c99ebcab1e0ae12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bcfd26cfb014a1c8e2a302978269600": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cd91bf2e9c746edb7517c257af1d038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd133078749241e89d16ebcf843c8f8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7259a63d8ac6457a8fb1c94985c21ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "218eee7ce90f4bdabae26d5f22c6411c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8c1e0449ad64c8392f2d09da1f59813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcfbe7afb410439488e3ed93a23d3a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ee860f899f340e4a53caec81530770a",
              "IPY_MODEL_d8dc2d024d6540cca429ff22cabf3b0f",
              "IPY_MODEL_c96032e17a40427790e317a574a0e062"
            ],
            "layout": "IPY_MODEL_ab80dc06dd5b495a800b957de5c2415e"
          }
        },
        "5ee860f899f340e4a53caec81530770a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3d23f94a2e1415d8bc0ce9ca0b503b2",
            "placeholder": "​",
            "style": "IPY_MODEL_458f41588fae4e3c810867e3d8594ebd",
            "value": "tokenizer.json: 100%"
          }
        },
        "d8dc2d024d6540cca429ff22cabf3b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0eac0717977464f8405438068fc87f3",
            "max": 1795303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_941fb51278554592b9fead32f877700d",
            "value": 1795303
          }
        },
        "c96032e17a40427790e317a574a0e062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6f1cd95f9404f3e9fef7fe1b075e4df",
            "placeholder": "​",
            "style": "IPY_MODEL_7289d86dc2344ce385ec6f606ead3335",
            "value": " 1.80M/1.80M [00:00&lt;00:00, 14.4MB/s]"
          }
        },
        "ab80dc06dd5b495a800b957de5c2415e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3d23f94a2e1415d8bc0ce9ca0b503b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "458f41588fae4e3c810867e3d8594ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0eac0717977464f8405438068fc87f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "941fb51278554592b9fead32f877700d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6f1cd95f9404f3e9fef7fe1b075e4df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7289d86dc2344ce385ec6f606ead3335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61eee79c118e46c8ab6ffaa03ea7d081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9cdc9bee06b45ce89704974dc92c42d",
              "IPY_MODEL_f098e7b04a0b4d74bee5bd9eb29ecea7",
              "IPY_MODEL_cd32f72a855b487a9601fce0f4a92e7a"
            ],
            "layout": "IPY_MODEL_800048d45f024d8298cf079945eadbee"
          }
        },
        "b9cdc9bee06b45ce89704974dc92c42d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7cea8dd7a8d4378bd970f38f62a7214",
            "placeholder": "​",
            "style": "IPY_MODEL_fb11dc47cf3640689cd4841938403317",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "f098e7b04a0b4d74bee5bd9eb29ecea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ee283be2f0c4046a1b68efefb044a91",
            "max": 72,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bab9b88e51c34544995aeb062e8b2182",
            "value": 72
          }
        },
        "cd32f72a855b487a9601fce0f4a92e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edebb9a869a1480aa7c4f9e9b30d6a36",
            "placeholder": "​",
            "style": "IPY_MODEL_5759f7569e604755a78f46167771bc31",
            "value": " 72.0/72.0 [00:00&lt;00:00, 4.06kB/s]"
          }
        },
        "800048d45f024d8298cf079945eadbee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7cea8dd7a8d4378bd970f38f62a7214": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb11dc47cf3640689cd4841938403317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ee283be2f0c4046a1b68efefb044a91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bab9b88e51c34544995aeb062e8b2182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "edebb9a869a1480aa7c4f9e9b30d6a36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5759f7569e604755a78f46167771bc31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eli-jaffe/SIOP-ML-Competition-2024/blob/main/SIOP_ML_Competition_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mixtral in Colab\n",
        "\n",
        "Welcome! In this notebook you can run [Mixtral8x7B-Instruct](https://huggingface.co/mistralai/Mixtral-8x7B-v0.1) with decent generation speed **right in Google Colab or on a consumer-grade GPU**. This was made possible by quantizing the original model in mixed precision and implementing a MoE-specific offloading strategy.\n",
        "\n",
        "To learn more, read our [tech report](https://arxiv.org/abs/2312.17238) or check out the [repo](https://github.com/dvmazur/mixtral-offloading) on GitHub."
      ],
      "metadata": {
        "id": "OW1moHJ1TdhO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One will need approximately 16 GB of VRAM and 11 GB of RAM to run this notebook and generate somewhat long texts.\n",
        "\n",
        "\n",
        "<details>\n",
        "\n",
        "<summary>How to balance between RAM and GPU VRAM usage</summary>\n",
        "\n",
        "You can balance between RAM and GPU VRAM usage by changing <code>offload_per_layer</code> variable in the <a href=\"#scrollTo=_mIpePTMFyRY&line=10&uniqifier=1\">Initialize model</a> section. Increasing <code>offload_per_layer</code> will decrease GPU VRAM usage, increase RAM usage and decrease generation speed. Decreasing <code>offload_per_layer</code> will have the opposite effect.\n",
        "\n",
        "Note that this notebook should run normally in Google Colab with <code>offload_per_layer = 4</code>, but may crush with other values. However, if you run this somewhere else, you're free to play with this variable.\n",
        "</details>"
      ],
      "metadata": {
        "id": "2-dvAX_hKZT4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and import libraries"
      ],
      "metadata": {
        "id": "Y8MhvkC7TKEL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7qY7ebqX7T7"
      },
      "outputs": [],
      "source": [
        "# fix numpy in colab\n",
        "import numpy\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# fix triton in colab\n",
        "!export LC_ALL=\"en_US.UTF-8\"\n",
        "!export LD_LIBRARY_PATH=\"/usr/lib64-nvidia\"\n",
        "!export LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs\"\n",
        "!ldconfig /usr/lib64-nvidia\n",
        "\n",
        "!git clone https://github.com/dvmazur/mixtral-offloading.git --quiet\n",
        "!cd mixtral-offloading && pip install -q -r requirements.txt\n",
        "!huggingface-cli download lavawolfiee/Mixtral-8x7B-Instruct-v0.1-offloading-demo --quiet --local-dir Mixtral-8x7B-Instruct-v0.1-offloading-demo\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"mixtral-offloading\")\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from hqq.core.quantize import BaseQuantizeConfig\n",
        "from huggingface_hub import snapshot_download\n",
        "from IPython.display import clear_output\n",
        "from tqdm.auto import trange\n",
        "from transformers import AutoConfig, AutoTokenizer\n",
        "from transformers.utils import logging as hf_logging\n",
        "\n",
        "from src.build_model import OffloadConfig, QuantConfig, build_model"
      ],
      "metadata": {
        "id": "GgpjnV7fV49W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212,
          "referenced_widgets": [
            "d290d4723f514358ad402b2c0fa0e33d",
            "97f1ad77a933426f9eb4f8265514393d",
            "454d4450faf4466b9fd6b21b2fb4c5f9",
            "20ad322c048d4e2f87a5333e52a431dc",
            "e151d66df18c448ab1b64958abf99cd3",
            "ed9dc324e9244c6fa9e3ca8c651d5583",
            "490498a144ae4117bee9bcc668d851e7",
            "0f568d46c6d7433eb20f01804ee9fd07",
            "7c14141967c644e5bdb75002c12a173e",
            "1fca159acd944907913b29bd226282c7",
            "058beab893a44f44b5c271dd9b30704b"
          ]
        },
        "outputId": "3f9e1f7d-280a-4a9f-f373-1568aae6f17f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hqq_aten package not installed. HQQBackend.ATEN backend will not work unless you install the hqq_aten lib in hqq/kernels.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d290d4723f514358ad402b2c0fa0e33d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextStreamer\n",
        "import datetime\n",
        "import gc\n",
        "\n",
        "import re\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "64BgrWog5NmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize model"
      ],
      "metadata": {
        "id": "OkSYibHcTQsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "quantized_model_name = \"lavawolfiee/Mixtral-8x7B-Instruct-v0.1-offloading-demo\"\n",
        "state_path = \"Mixtral-8x7B-Instruct-v0.1-offloading-demo\"\n",
        "\n",
        "config = AutoConfig.from_pretrained(quantized_model_name)\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "##### Change this to 5 if you have only 12 GB of GPU VRAM #####\n",
        "offload_per_layer = 4\n",
        "# offload_per_layer = 5\n",
        "###############################################################\n",
        "\n",
        "num_experts = config.num_local_experts\n",
        "print(f\"Using {num_experts} experts\")\n",
        "\n",
        "offload_config = OffloadConfig(\n",
        "    main_size=config.num_hidden_layers * (num_experts - offload_per_layer),\n",
        "    offload_size=config.num_hidden_layers * offload_per_layer,\n",
        "    buffer_size=4,\n",
        "    offload_per_layer=offload_per_layer,\n",
        ")\n",
        "\n",
        "\n",
        "attn_config = BaseQuantizeConfig(\n",
        "    nbits=4,\n",
        "    group_size=64,\n",
        "    quant_zero=True,\n",
        "    quant_scale=True,\n",
        ")\n",
        "attn_config[\"scale_quant_params\"][\"group_size\"] = 256\n",
        "\n",
        "\n",
        "ffn_config = BaseQuantizeConfig(\n",
        "    nbits=2,\n",
        "    group_size=16,\n",
        "    quant_zero=True,\n",
        "    quant_scale=True,\n",
        ")\n",
        "quant_config = QuantConfig(ffn_config=ffn_config, attn_config=attn_config)\n",
        "\n",
        "\n",
        "model = build_model(\n",
        "    device=device,\n",
        "    quant_config=quant_config,\n",
        "    offload_config=offload_config,\n",
        "    state_path=state_path,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262,
          "referenced_widgets": [
            "7fa36aa363d34a2f9e81c958e12f7036",
            "cbf11a6fd4d541119856eab1b72fd1ce",
            "3b0abf10257642d0b524e8ef1fd80abe",
            "4ddd0627d2ec46a3b4079f88ce3b0998",
            "65b8d5c7985d475f8e62e64162b7d941",
            "ddabb48dc0014d41b46eab8b4e5313ee",
            "b3634bf9f2744c429387fdfdc9e26035",
            "b76d8776c6a3425f82b84f7f4bbf66a6",
            "729054f23c1c4789a6dd661026154296",
            "61d7521d28404fbd88b419cc68308fda",
            "1a7111a2a1904459a26665aa896f85b2",
            "f6c9ecdd1bc94bc9b0a8d89b1ebdf79b",
            "4c9c49144a0a4f5198e30eb799e5e7c4",
            "d267a1e56071491dbcd819539fb297fc",
            "5f97fa43b53b42949455ad182dbfa11a",
            "7b1cf5db95044abea5515bd30569a6db",
            "cd675ac722d5402aa10be2c13706284d",
            "0d9721aa908840498d42ac64bd47a441",
            "d29ce4e7877446018b3501f9689090d1",
            "c6a24f2f66694ad381b6dcb4156ab011",
            "c2b0b8c62e9f49c4aeccce35a27bdda4",
            "79ac76eb473a48a6a0a2c20d2fde6af6"
          ]
        },
        "id": "_mIpePTMFyRY",
        "outputId": "f0dad1fc-fe5a-43bb-b640-78b6186a3b40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 8 experts\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/720 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fa36aa363d34a2f9e81c958e12f7036"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
            "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading experts:   0%|          | 0/32 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6c9ecdd1bc94bc9b0a8d89b1ebdf79b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a function that scans a text input for the sequence \"[/INST] \" and returns only the portion that comes after that\n",
        "\n",
        "def extract_after_inst(text):\n",
        "  \"\"\"\n",
        "  Extracts the portion of text that comes after the sequence \"[/INST] \".\n",
        "\n",
        "  Args:\n",
        "    text: The input text string.\n",
        "\n",
        "  Returns:\n",
        "    The portion of text after \"[/INST] \", or None if the sequence is not found.\n",
        "  \"\"\"\n",
        "\n",
        "  index = text.find(\"[/INST] \")\n",
        "  if index != -1:\n",
        "    return text[index + len(\"[/INST] \"):]\n",
        "  else:\n",
        "    return None\n",
        "\n",
        "# # Example usage:\n",
        "# text = \"This is some text before [/INST] and this is some text after.\"\n",
        "# extracted_text = extract_after_inst(text)\n",
        "# print(extracted_text)  # Output: \"and this is some text after.\"\n",
        "\n",
        "# text = \"This text does not contain the sequence.\"\n",
        "# extracted_text = extract_after_inst(text)\n",
        "# print(extracted_text)  # Output: None\n"
      ],
      "metadata": {
        "id": "8QZXdLgS_5o5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a function that takes a string of correct or incorrect json and returns the relevant information. The input string always starts  with '''\"empathy\"\\n\"present\": \"<str>\"''' where <str> represents a string of text. Sometimes that is the end of the input but sometimes there is more text afterwards. This function should return the value of the <str> within the quotation marks after \"present\":\n",
        "\n",
        "import re\n",
        "\n",
        "def extract_predicted_value(json_string, keyword):\n",
        "  \"\"\"\n",
        "  Extracts the value of the \"present\" key from a JSON string.\n",
        "\n",
        "  Args:\n",
        "    json_string: A string containing a JSON object.\n",
        "\n",
        "  Returns:\n",
        "    The value of the \"present\" key, or None if the key is not found.\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  match = re.search(rf'\"{keyword}\":\\s*\"([^\"]*)\"', json_string)\n",
        "  if match:\n",
        "    return match.group(1)\n",
        "  else:\n",
        "    return None\n",
        "\n",
        "# # Example usage:\n",
        "# json_string = '''\"present\": \"0\"'''\n",
        "# present_value = extract_empathy_value(json_string)\n",
        "# print(present_value)  # Output: 0\n",
        "\n",
        "# json_string = '''\"empathy\": \"1\"'''\n",
        "# present_value = extract_empathy_value(json_string)\n",
        "# print(present_value)  # Output: 1\n",
        "\n",
        "# json_string = '''\"empathy\": \"How are you today?\"'''\n",
        "# present_value = extract_empathy_value(json_string)\n",
        "# print(present_value)  # Output: How are you today?\n"
      ],
      "metadata": {
        "id": "pYy2NcBoAGd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount your Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "outputId": "88b5e539-eb44-439d-b19d-4f27fb9db644",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-x1WU8LXKH8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Empathy"
      ],
      "metadata": {
        "id": "5rbsoYkdwWbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "empathy = pd.read_csv('/content/drive/MyDrive/SIOP-ML-2024/data/empathy_val_public.csv')"
      ],
      "metadata": {
        "id": "vMg_H-I8XKH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def empathy_instruction_format(sys_message: str, query: str):\n",
        "    # note, don't \"</s>\" to the end\n",
        "    return f'<s> [INST] {sys_message} [/INST]\\nUser: {query}\\nAssistant: ```\\n{{\\n\"empathy\": '\n"
      ],
      "metadata": {
        "id": "vSahRv2P-PUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys_msg = \"\"\"\n",
        "You are an expert AI assistant. Your job is to help HR professionals review job candidate responses to a difficult workplace situation and determine whether empathy was demonstrated or not. You are reviewing only the open text response to the question.\n",
        "\n",
        "For context, emotion researchers generally define empathy as \"the ability to sense other people's emotions, coupled with the ability to imagine what someone else might be thinking or feeling\". When reviewing responses, there are a couple of signs to look out for:\n",
        "\n",
        "Signs of empathy:\n",
        "-Perspective taking\n",
        "-kind language\n",
        "-empathy towards the subject\n",
        "-empathy towards other people mentioned in the response\n",
        "\n",
        "Signs of low emapthy:\n",
        "-curt or overly direct language\n",
        "-creating a sense of urgency\n",
        "-making demands\n",
        "\n",
        "Remember, only consider the content of the response. Do not consider the quality of the spelling, grammar, or punctuation.\n",
        "\n",
        "You must always respond in JSON format containing a key-value pair with the key `\"empathy\"`. If you detect that empathy was demonstrated, you must respond with `\"empathy\": \"1\"`. If you detect that empathy was not demonstrated, you must respond with `\"empathy\": \"0\"`.\n",
        "\n",
        "Do not provide any other information in the response. Do not provide an explanation for your decision. Do not try to answer the user. Keep your response as short and concise as possible.\n",
        "\n",
        "For example, to respond to the prompt, \"Hi Jonathan, I wanted to have  a discussion with you but since you are travelling i am sharing in this mailThis is related to Beta project and reports coming from there.While we are all excited by the passion and enthusiasm you are bringing i wanted to share some early feedback with you. 1.Please try to be concise in reports and mention facts that teams can refer . We love opinions but lets save those for our brainstorming discussions. 2.For Business writing as you are getting started to help you set up for success we are nominating you for a training program so that your reports are way more effective. I hope as you set on your growth journey and take larger roles a superb feedback from your peers and stakeholders will help. I truly believe above two points can really help you take you there. Wishing you all the best and do share in case you have feedback or inputs from your side. Regards William\" you must respond like so:\n",
        "\n",
        "```\n",
        "{\n",
        "    \"empathy\": \"1\"\n",
        "}\n",
        "```\n",
        "\n",
        "Or to answer the prompt \"Hi Jonathan, How are You doing with the Beta project? It seams You are very exited about the project.There are two topics that I want to point out that I expct to be Your focus on this project.I review the latest report and saw that in addition to a tchnical information that we have agreed to be included in that, there is a lots of commentaries from Your side. It is greeate that You see the opportunities and perspectives on the findings but I ask You to focus on collecting and passing on the technical information according to the agreed template. We can focus on Your ideas separately once the Beta gets to that stage.The second thing I'd like you to focus is the organizing the details in the reports. Please work together with Terry on that. As the deadlines for presenting the reports to CEO are quite challenging, they have lost of hints and tricks how to make the report informative and easy to read. I've have used his experience and competence myself. It is very important that we submit the report on time. Please add me as well to the reciepient list once You send the infotmation to Terry. Good luck!\" you must respond:\n",
        "\n",
        "```\n",
        "{\n",
        "    \"empathy\": \"0\"\n",
        "}\n",
        "```\n",
        "\n",
        "Remember, even when answering to the user, you must still use this JSON format! You must always provide an `\"emapthy\"` value of `\"1\"` or `\"0\"`. If you'd like to ask how the user is doing you must write:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"empathy\": \"1\"\n",
        "    \"message\": \"How are you today?\"\n",
        "}\n",
        "```\n",
        "\n",
        "Let's get started. The response prompt is as follows.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "I3iZauCn-RjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys_msg_try_next = \"\"\"\n",
        "You are an expert AI assistant. Your job is to help HR professionals review job candidate responses to a difficult workplace situation and determine whether empathy was demonstrated or not. You are reviewing only the open text response to the question.\n",
        "\n",
        "For context, emotion researchers generally define empathy as \"the ability to sense other people's emotions, coupled with the ability to imagine what someone else might be thinking or feeling\". When reviewing responses, there are a couple of signs to look out for:\n",
        "\n",
        "Signs of empathy:\n",
        "-Perspective taking\n",
        "-kind language\n",
        "-empathy towards the subject\n",
        "-empathy towards other people mentioned in the response\n",
        "\n",
        "Signs of low emapthy:\n",
        "-curt or overly direct language\n",
        "-creating a sense of urgency\n",
        "-making demands\n",
        "\n",
        "Remember, only consider the content of the response. Do not consider the quality of the spelling, grammar, or punctuation.\n",
        "\n",
        "You must always respond in JSON format containing a key-value pair with the key `\"empathy\"`. If you detect that empathy was demonstrated, you must respond with `\"empathy\": \"1\"`. If you detect that empathy was not demonstrated, you must respond with `\"empathy\": \"0\"`.\n",
        "\n",
        "\n",
        "For example, to respond to the prompt, \"Hi Jonathan, I wanted to have  a discussion with you but since you are travelling i am sharing in this mailThis is related to Beta project and reports coming from there.While we are all excited by the passion and enthusiasm you are bringing i wanted to share some early feedback with you. 1.Please try to be concise in reports and mention facts that teams can refer . We love opinions but lets save those for our brainstorming discussions. 2.For Business writing as you are getting started to help you set up for success we are nominating you for a training program so that your reports are way more effective. I hope as you set on your growth journey and take larger roles a superb feedback from your peers and stakeholders will help. I truly believe above two points can really help you take you there. Wishing you all the best and do share in case you have feedback or inputs from your side. Regards William\" you must respond like so:\n",
        "\n",
        "```\n",
        "{\n",
        "    \"empathy\": \"1\"\n",
        "}\n",
        "```\n",
        "\n",
        "Or to answer the prompt \"Hi Jonathan, How are You doing with the Beta project? It seams You are very exited about the project.There are two topics that I want to point out that I expct to be Your focus on this project.I review the latest report and saw that in addition to a tchnical information that we have agreed to be included in that, there is a lots of commentaries from Your side. It is greeate that You see the opportunities and perspectives on the findings but I ask You to focus on collecting and passing on the technical information according to the agreed template. We can focus on Your ideas separately once the Beta gets to that stage.The second thing I'd like you to focus is the organizing the details in the reports. Please work together with Terry on that. As the deadlines for presenting the reports to CEO are quite challenging, they have lost of hints and tricks how to make the report informative and easy to read. I've have used his experience and competence myself. It is very important that we submit the report on time. Please add me as well to the reciepient list once You send the infotmation to Terry. Good luck!\" you must respond:\n",
        "\n",
        "```\n",
        "{\n",
        "    \"empathy\": \"0\"\n",
        "}\n",
        "```\n",
        "\n",
        "Remember, even when answering to the user, you must still use this JSON format! You must always provide an `\"emapthy\"` value of `\"1\"` or `\"0\"`. If you'd like to ask how the user is doing you must write:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"empathy\": \"1\"\n",
        "    \"message\": \"How are you today?\"\n",
        "}\n",
        "```\n",
        "\n",
        "Let's get started. The response prompt is as follows.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "1m9RwYOON11T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys_msg_old = \"\"\"\n",
        "You are an expert AI assistant. Your job is to help HR professionals review job candidate responses to a difficult workplace situation and determine whether empathy was demonstrated or not. You are reviewing only the open text response to the question.\n",
        "\n",
        "For context, emotion researchers generally define empathy as \"the ability to sense other people's emotions, coupled with the ability to imagine what someone else might be thinking or feeling\". When reviewing responses, there are a couple of signs to look out for:\n",
        "\n",
        "Signs of empathy:\n",
        "-Perspective taking\n",
        "-kind language\n",
        "-empathy towards the subject\n",
        "-empathy towards other people mentioned in the response\n",
        "\n",
        "Signs of low emapthy:\n",
        "-curt or overly direct language\n",
        "-creating a sense of urgency\n",
        "-making demands\n",
        "\n",
        "Remember, only consider the content of the response. Do not consider the quality of the spelling, grammar, or punctuation.\n",
        "\n",
        "Here is a sample of survey responses and whether empathy was demonstrated (1) or not (0). The correct answer is provided after the `---` following each prompt.\n",
        "\n",
        "Hi Jonathan, I hope this message finds you well. I hear things are going well with the Beta project. That said, Terry mentioned that there were some issues with the reports. From what I understand, they would like them to be more concise and straight to the point, as well as more business focused. I recommend you reach out to Terry so you both could review in detail one of the reports he submits. This should help you help you align to their expectations. Additionally, i'd be happy to review the reports before you send them off to Terry and provide my feedback. I know this  project is important to you, so please let me know how this meeting goes and how else I can help. Regards, William --- 1\n",
        "Jonathan, I hope you are well - I am very excited that you are part of this development team and really appreciate all the support you give to us; while doing this some comments have arise that can be  opportunity areas to improve your work and get this program ahead.1. The communication between team members is not clear and improvements can be done to this: by this I mean to connect more with other team members before submitting your reports.2. One of the reasons you were chosen is because of your enthusiastic attitude and knowledge, but too much information sometimes can harm the delivery reports that needs to be concise and business oriented. 3.Please forward me your latest report so we can discuss it furthermore when I come back and see what can be improve and we can work from there.4. Please don't be discourage, these are opportunity areas that we can engage and as always keep up the good work. Have a great week. Thanks --- 1\n",
        "Jonathan, First I want to thank you for your help with the Beta project.  However,  it has been brought to my attention that perhaps ABC-5 didn't do enough to prepare you for the extra work and I would like to discuss some issues. The nature of these reports requires them to be technical in nature.  Your insights are very valuable and much appreciated but as the old line goes \"please give me just the facts\".  Given the critical nature of the information you are providing I can't stress the importance of concise yet detail factual reports.  I would like to review your reports as a training exercise to help you better meet the team requirements.  Given that there are some major reports coming up in the immediate future, I would like you to review some training options and then present a report for review.  Again your insights are appreciated but we need to make sure we are presenting the end-use with only the information they need to make a sound business decision. I also understand you would like to grow into a leadership position so I would like to discuss how successfully implementing these changes would be beneficial in demonstrating an ability to grow and take on new challenges. --- 0\n",
        "Hi Jonathan, How are You doing with the Beta project? It seams You are very exited about the project.There are two topics that I want to point out that I expct to be Your focus on this project.I review the latest report and saw that in addition to a tchnical information that we have agreed to be included in that, there is a lots of commentaries from Your side. It is greeate that You see the opportunities and perspectives on the findings but I ask You to focus on collecting and passing on the technical information according to the agreed template. We can focus on Your ideas separately once the Beta gets to that stage.The second thing I'd like you to focus is the organizing the details in the reports. Please work together with Terry on that. As the deadlines for presenting the reports to CEO are quite challenging, they have lost of hints and tricks how to make the report informative and easy to read. I've have used his experience and competence myself. It is very important that we submit the report on time. Please add me as well to the reciepient list once You send the infotmation to Terry. Good luck! --- 0\n",
        "\n",
        "You must always respond in JSON format containing a key-value pair with the key `\"empathy\"`. If you detect that empathy was demonstrated, you must respond with `\"empathy\": \"1\"`. If you detect that empathy was not demonstrated, you must respond with `\"empathy\": \"0\"`.\n",
        "\n",
        "Do not provide any other information in the response. Do not provide an explanation for your decision. Do not try to answer the user. Keep your response as short and concise as possible.\n",
        "\n",
        "For example, to respond to the prompt, \"Hi Jonathan, I wanted to have  a discussion with you but since you are travelling i am sharing in this mailThis is related to Beta project and reports coming from there.While we are all excited by the passion and enthusiasm you are bringing i wanted to share some early feedback with you. 1.Please try to be concise in reports and mention facts that teams can refer . We love opinions but lets save those for our brainstorming discussions. 2.For Business writing as you are getting started to help you set up for success we are nominating you for a training program so that your reports are way more effective. I hope as you set on your growth journey and take larger roles a superb feedback from your peers and stakeholders will help. I truly believe above two points can really help you take you there. Wishing you all the best and do share in case you have feedback or inputs from your side. Regards William\" you must respond like so:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"empathy\": \"1\"\n",
        "}\n",
        "```\n",
        "\n",
        "Or to answer the prompt \"Hi Jonathan, I hope you're having safe travels along your way. I'm reaching out to you because you are a valued employee, and we appreciate your hard work and research. While I understand you are passionate about these projects, it is imperative that you keep your reports concise, seeing as we are all continuously on a time crunch. Because these reports are not written as efficiently as possible, it is taking too much of our time to read and determine which bit of information is most valuable. I need you to shift the way you are writing these reports so that way we can maximize our work flow processes. We love having you on our team, but if you can not make these necessary changes, we may have to relocate your skill set to a different department. However, I am positive you can make these minor changes in the way you create your reports. Please research the formal way to write reports so that way you no longer add too much information. These reports should have less opinions, and more facts. I will also send some material for you to review on how to keep these reports business friendly. I love your passion and your drive, I am hoping we can continue to have you on this project. A few minor changes will be all it takes to get the ball rolling in the right direction! If you have any concerns, feel free to reach out to me and I will be more than happy to assist. Thank you, William\" you must respond:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"empathy\": \"1\"\n",
        "}\n",
        "```\n",
        "\n",
        "Remember, even when answering to the user, you must still use this JSON format! You must always provide an `\"emapthy\"` value of `\"1\"` or `\"0\"`. If you'd like to ask how the user is doing you must write:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"empathy\": \"1\"\n",
        "    \"message\": \"How are you today?\"\n",
        "}\n",
        "```\n",
        "\n",
        "Finally, your answer should never exceed 100 character. If it does, you will be penalized.\n",
        "\n",
        "Let's get started. The response prompt is as follows.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "Uo11QVW9oE_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a function that takes a string of correct or incorrect json and returns the relevant information. The input string always starts  with '''\"empathy\"\\n\"present\": \"<str>\"''' where <str> represents a string of text. Sometimes that is the end of the input but sometimes there is more text afterwards. This function should return the value of the <str> within the quotation marks after \"present\":\n",
        "\n",
        "import re\n",
        "\n",
        "def extract_predicted_value(json_string, keyword):\n",
        "  \"\"\"\n",
        "  Extracts the value of the \"present\" key from a JSON string.\n",
        "\n",
        "  Args:\n",
        "    json_string: A string containing a JSON object.\n",
        "\n",
        "  Returns:\n",
        "    The value of the \"present\" key, or None if the key is not found.\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  match = re.search(rf'\"{keyword}\":\\s*\"([^\"]*)\"', json_string)\n",
        "  if match:\n",
        "    return match.group(1)\n",
        "  else:\n",
        "    return None\n",
        "\n",
        "# # Example usage:\n",
        "# json_string = '''\"present\": \"0\"'''\n",
        "# present_value = extract_empathy_value(json_string)\n",
        "# print(present_value)  # Output: 0\n",
        "\n",
        "# json_string = '''\"empathy\": \"1\"'''\n",
        "# present_value = extract_empathy_value(json_string)\n",
        "# print(present_value)  # Output: 1\n",
        "\n",
        "# json_string = '''\"empathy\": \"How are you today?\"'''\n",
        "# present_value = extract_empathy_value(json_string)\n",
        "# print(present_value)  # Output: How are you today?\n"
      ],
      "metadata": {
        "id": "tdA_O9OiFzFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a function that scans a text input for the sequence \"[/INST] \" and returns only the portion that comes after that\n",
        "\n",
        "def extract_after_inst(text):\n",
        "  \"\"\"\n",
        "  Extracts the portion of text that comes after the sequence \"[/INST] \".\n",
        "\n",
        "  Args:\n",
        "    text: The input text string.\n",
        "\n",
        "  Returns:\n",
        "    The portion of text after \"[/INST] \", or None if the sequence is not found.\n",
        "  \"\"\"\n",
        "\n",
        "  index = text.find(\"[/INST] \")\n",
        "  if index != -1:\n",
        "    return text[index + len(\"[/INST] \"):]\n",
        "  else:\n",
        "    return None\n",
        "\n",
        "# # Example usage:\n",
        "# text = \"This is some text before [/INST] and this is some text after.\"\n",
        "# extracted_text = extract_after_inst(text)\n",
        "# print(extracted_text)  # Output: \"and this is some text after.\"\n",
        "\n",
        "# text = \"This text does not contain the sequence.\"\n",
        "# extracted_text = extract_after_inst(text)\n",
        "# print(extracted_text)  # Output: None\n"
      ],
      "metadata": {
        "id": "kppXx0yUEM_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "empathy = empathy.iloc[:2]"
      ],
      "metadata": {
        "id": "8GtKam9OJ-rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(empathy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfNSLYpMLAFe",
        "outputId": "0ceb075e-e2f1-43bc-f16a-09b9326144fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a function that finds the first 0 or 1 in a string\n",
        "\n",
        "import re\n",
        "\n",
        "def find_first_0_or_1(text):\n",
        "    match = re.search(r'[01]', text)\n",
        "    if match:\n",
        "        return match.group(0)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Example usage:\n",
        "text = '\"empathy\": \"0\"'\n",
        "first_digit = find_first_0_or_1(text)\n",
        "print(first_digit)  # Output: 0\n",
        "\n",
        "text = '\"empathy\": \"1\"'\n",
        "first_digit = find_first_0_or_1(text)\n",
        "print(first_digit)  # Output: 1\n",
        "\n",
        "text = '\"empathy\": \"How are you today?\"'\n",
        "first_digit = find_first_0_or_1(text)\n",
        "print(first_digit)  # Output: None\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XucBrMSQOczt",
        "outputId": "f6ab3f18-0804-4033-9e75-a24924dc5e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextStreamer\n",
        "import datetime\n",
        "import gc\n",
        "\n",
        "def predict_empathy(data, iteration):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "  streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
        "\n",
        "  past_key_values = None\n",
        "  sequence = None\n",
        "\n",
        "  seq_len = 0\n",
        "\n",
        "  results = []\n",
        "\n",
        "  for index, resp in data.iterrows():\n",
        "\n",
        "\n",
        "    # gc.collect()\n",
        "\n",
        "    # if torch.cuda.is_available():\n",
        "    #   torch.cuda.empty_cache()\n",
        "    #   gc.collect()\n",
        "\n",
        "    print(f'Analyzing response {index+1} / {len(data)}')\n",
        "    user_entry = dict(role=\"user\", content=empathy_instruction_format(sys_msg, resp.text))\n",
        "    input_ids = tokenizer.apply_chat_template([user_entry], return_tensors=\"pt\").to(device)\n",
        "\n",
        "    if past_key_values is None:\n",
        "      attention_mask = torch.ones_like(input_ids)\n",
        "    else:\n",
        "      seq_len = input_ids.size(1) + past_key_values[0][0][0].size(1)\n",
        "      attention_mask = torch.ones([1, seq_len - 1], dtype=torch.int, device=device)\n",
        "\n",
        "    print(\"Mixtral: \", end=\"\")\n",
        "    result = model.generate(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      past_key_values=past_key_values,\n",
        "      streamer=streamer,\n",
        "      do_sample=True,\n",
        "      temperature=0.9,\n",
        "      top_p=0.9,\n",
        "      max_new_tokens=15,\n",
        "      pad_token_id=tokenizer.eos_token_id,\n",
        "      return_dict_in_generate=True,\n",
        "      output_hidden_states=False,\n",
        "    )\n",
        "\n",
        "    #print(extract_after_inst(tokenizer.decode(result[\"sequences\"][0])))\n",
        "    #print(extract_present_value(tokenizer.decode(result[0])))\n",
        "    #results.append(extract_present_value(tokenizer.decode(result[0])))\n",
        "    results.append([resp._id,\n",
        "                    find_first_0_or_1(\n",
        "                        extract_after_inst(\n",
        "                            tokenizer.decode(\n",
        "                                result[\"sequences\"][0], skip_special_tokens=True)\n",
        "                            )),\n",
        "                    extract_after_inst(tokenizer.decode(\n",
        "                                result[\"sequences\"][0], skip_special_tokens=True))\n",
        "                    ])\n",
        "\n",
        "    del result\n",
        "    del attention_mask\n",
        "    del input_ids\n",
        "    del user_entry\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "  print('Results collected. Building dataframe')\n",
        "  df = pd.DataFrame(results, columns = ['_id', 'empathy', 'full_text'])\n",
        "  fname = f'/content/drive/MyDrive/SIOP-ML-2024/empathy_results_iteration{iteration}_{datetime.datetime.now()}.csv'\n",
        "  df.to_csv(fname, index=False)\n",
        "  print(f'Results saved to {fname}')\n",
        "\n",
        "  return df\n",
        "\n",
        "df1 = predict_empathy(empathy, 1)\n",
        "\n",
        "# test = empathy.copy()\n",
        "# test['text'][test._id == 198 ] = 'screw you idiot'\n",
        "\n",
        "df2 = predict_empathy(empathy, 2)\n",
        "# df2['empathy'][df2._id == 198] = '0'\n",
        "\n",
        "tiebreaker = predict_empathy(empathy[empathy._id.isin(df1[df1.empathy != df2.empathy]._id)], 3)\n",
        "\n",
        "\n",
        "if len(tiebreaker) > 0:\n",
        "  final_empathy = pd.concat(\n",
        "      [df1[df1.empathy == df2.empathy],\n",
        "      tiebreaker]).sort_values(by=['_id'], ascending=True)\n",
        "\n",
        "  final_empathy.reset_index(drop=True, inplace=True)\n",
        "\n",
        "else:\n",
        "  final_empathy = df1\n",
        "\n",
        "\n",
        "final_empathy.to_csv(f'/content/drive/MyDrive/SIOP-ML-2024/empathy_results_final_{datetime.datetime.now()}.csv', index=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6c2168c-4cfb-4c20-ec95-0f82ca8b848e",
        "id": "pWLUGoUrXKH9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing response 1 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "In the response provided,\n",
            "Analyzing response 2 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "Explanation: The response\n",
            "Analyzing response 3 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "### Reasoning\n",
            "\n",
            "Analyzing response 4 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "Explanation: In this\n",
            "Analyzing response 5 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "(Note: I am\n",
            "Analyzing response 6 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "Explanation: HR manager\n",
            "Analyzing response 7 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "Comment: This response is considered\n",
            "Analyzing response 8 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "[earwig]\n",
            "Analyzing response 9 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "\n",
            "The response demonstrates empathy through perspective\n",
            "Analyzing response 10 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "Reason: The content demonstr\n",
            "Analyzing response 11 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "The response shows signs of\n",
            "Analyzing response 12 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "Given William's patient\n",
            "Analyzing response 13 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "## Explanation\n",
            "\n",
            "Analyzing response 14 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "Explanation:\n",
            "In\n",
            "Analyzing response 15 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "Analyzing response 16 / 70\n",
            "Mixtral: \"1\"\n",
            "}  ```\n",
            "**Explaination:** This response\n",
            "Analyzing response 17 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "Comment: This response shows\n",
            "Analyzing response 18 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```As the response demonstrates empathy\n",
            "Analyzing response 19 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "[Considering the content\n",
            "Analyzing response 20 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```This response shows empathy by acknowled\n",
            "Analyzing response 21 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```As a hiring manager, William is\n",
            "Analyzing response 22 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "### Explanation of\n",
            "Analyzing response 23 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "In this response, the\n",
            "Analyzing response 24 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "** Signs of Emp\n",
            "Analyzing response 25 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "* This response demonstrates\n",
            "Analyzing response 26 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "Explanation:\n",
            "Even\n",
            "Analyzing response 27 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "```json\n",
            "Ex\n",
            "Analyzing response 28 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "\n",
            "```[Explanation](https\n",
            "Analyzing response 29 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "```\n",
            "Analyzing response 30 / 70\n",
            "Mixtral: \"1\"\n",
            "} \n",
            "# Assistants do not have emotions\n",
            "Analyzing response 31 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "This response is considered em\n",
            "Analyzing response 32 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "### Signs of em\n",
            "Analyzing response 33 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "* This response demonstrates\n",
            "Analyzing response 34 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "Explanation: The response\n",
            "Analyzing response 35 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "\n",
            "```\n",
            "Analyzing response 36 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "In this case, em\n",
            "Analyzing response 37 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "Explanation:\n",
            "\n",
            "\n",
            "Analyzing response 38 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "The user expresses understanding\n",
            "Analyzing response 39 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "Explanation: In\n",
            "Analyzing response 40 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "User's feedback shows\n",
            "Analyzing response 41 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "\n",
            "```\n",
            "\n",
            "Comment: This response\n",
            "Analyzing response 42 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "Comment: This response shows\n",
            "Analyzing response 43 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "Perspective-taking\n",
            "Analyzing response 44 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "Here's the r\n",
            "Analyzing response 45 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "Explanation: This response\n",
            "Analyzing response 46 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "```**[Day\n",
            "Analyzing response 47 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "Comment: This response demonstrates\n",
            "Analyzing response 48 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "[My commentary on\n",
            "Analyzing response 49 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "Comment: The response is overall\n",
            "Analyzing response 50 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "\n",
            "[based on the overall understanding and supportive\n",
            "Analyzing response 51 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "**Explanation:** This\n",
            "Analyzing response 52 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "**Prompt:** [U\n",
            "Analyzing response 53 / 70\n",
            "Mixtral: \"0\"\n",
            "}\n",
            "\n",
            "```\n",
            "\n",
            "The response does not\n",
            "Analyzing response 54 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```Apologies if this is delayed.\n",
            "Analyzing response 55 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "As a helpful assistant, I try\n",
            "Analyzing response 56 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "Explanation: This response\n",
            "Analyzing response 57 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "\n",
            "```[it looks like you accidentally\n",
            "Analyzing response 58 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "\n",
            "```\n",
            "Analyzing response 59 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "## Analyzing the\n",
            "Analyzing response 60 / 70\n",
            "Mixtral: \"1\"\n",
            "} \n",
            "\n",
            "The assistant has indicated empathy by\n",
            "Analyzing response 61 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "\n",
            "### Explanation\n",
            "\n",
            "In this\n",
            "Analyzing response 62 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "```\n",
            "\n",
            "Ex\n",
            "Analyzing response 63 / 70\n",
            "Mixtral: \"0\"\n",
            "}\n",
            "\n",
            "[assistant] In this scenario,\n",
            "Analyzing response 64 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "[body shocked, surprised\n",
            "Analyzing response 65 / 70\n",
            "Mixtral: \"0\"\n",
            "}\n",
            "```\n",
            "\n",
            "## Explanation\n",
            "\n",
            "Analyzing response 66 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "Reasoning: The user\n",
            "Analyzing response 67 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```As you have shown empathy towards\n",
            "Analyzing response 68 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "(In this case,\n",
            "Analyzing response 69 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "User: Hello William,\n",
            "Analyzing response 70 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "Explanation: The response\n",
            "Results collected. Building dataframe\n",
            "Results saved to /content/drive/MyDrive/SIOP-ML-2024/empathy_results_iteration1_2024-03-22 04:59:39.107658.csv\n",
            "Analyzing response 1 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "* This response demonstrates\n",
            "Analyzing response 2 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "\n",
            "```[upon seeing the signs\n",
            "Analyzing response 3 / 70\n",
            "Mixtral: \"1\"\n",
            "} \t\n",
            "Because the response shows signs of perspective\n",
            "Analyzing response 4 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "Comment: This response demonstrates\n",
            "Analyzing response 5 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "Explanation: The\n",
            "Analyzing response 6 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "In this response, the\n",
            "Analyzing response 7 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "## Prompt 1:\n",
            "Analyzing response 8 / 70\n",
            "Mixtral: \"1\"\n",
            "} ```\n",
            "\n",
            "This response is empathetic because it\n",
            "Analyzing response 9 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "Comment: This response demonstr\n",
            "Analyzing response 10 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "Explanation: The\n",
            "Analyzing response 11 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```Even though the feedback is related to\n",
            "Analyzing response 12 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "Signs of empathy:\n",
            "Analyzing response 13 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "## Why:\n",
            "This\n",
            "Analyzing response 14 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "In this response, the HR\n",
            "Analyzing response 15 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "**Signs of em\n",
            "Analyzing response 16 / 70\n",
            "Mixtral: \"1\"\n",
            "}  ```\n",
            "This response is considered empathetic because\n",
            "Analyzing response 17 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "The user has shown perspective\n",
            "Analyzing response 18 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```As the user has shown perspective taking\n",
            "Analyzing response 19 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "[type: emapthy\n",
            "Analyzing response 20 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "\n",
            "[`\"empathy\"` value of\n",
            "Analyzing response 21 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "``` as the response suggests, the writer\n",
            "Analyzing response 22 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "* This response demonstrates\n",
            "Analyzing response 23 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "(There are several indic\n",
            "Analyzing response 24 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "}\n",
            "\n",
            "### Re\n",
            "Analyzing response 25 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "In this response, em\n",
            "Analyzing response 26 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "Explanation:\n",
            "This\n",
            "Analyzing response 27 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "```json\n",
            "Ex\n",
            "Analyzing response 28 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "```\n",
            "Analyzing response 29 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "```\n",
            "Analyzing response 30 / 70\n",
            "Mixtral: \"1\"\n",
            "} \n",
            "\\cockroachont :]>\n",
            "Analyzing response 31 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "Explanation: This\n",
            "Analyzing response 32 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "* This response demonstrates em\n",
            "Analyzing response 33 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```As the assistant, I understand that\n",
            "Analyzing response 34 / 70\n",
            "Mixtral: \"1\"\n",
            "} \n",
            "Spelling, grammar, and punct\n",
            "Analyzing response 35 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "```\n",
            "Analyzing response 36 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "(Note: The user\n",
            "Analyzing response 37 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "The user has demonstrated em\n",
            "Analyzing response 38 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "(Even though this response\n",
            "Analyzing response 39 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "[Prompt discussion]\n",
            "Analyzing response 40 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "```\n",
            "[small\n",
            "Analyzing response 41 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "\n",
            "```[Explanation](#\n",
            "Analyzing response 42 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "Comment: This response shows\n",
            "Analyzing response 43 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "\n",
            "```\n",
            "\n",
            "**Reasoning:**\n",
            "Analyzing response 44 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "In this response, William\n",
            "Analyzing response 45 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "The user in this case\n",
            "Analyzing response 46 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "Explanation: This response\n",
            "Analyzing response 47 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "(Note: The decision\n",
            "Analyzing response 48 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "[For the sake of\n",
            "Analyzing response 49 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "fantastic that the\n",
            "Analyzing response 50 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "Analyzing response 51 / 70\n",
            "Mixtral: 1\n",
            "} \\`entrymode, html\\`\n",
            "\n",
            "[\n",
            "Analyzing response 52 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "**Reason:** The response shows\n",
            "Analyzing response 53 / 70\n",
            "Mixtral: \"0\"\n",
            "}\n",
            "Analyzing response 54 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```As a considerate and caring HR\n",
            "Analyzing response 55 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "Explanation: This response\n",
            "Analyzing response 56 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "The response shows empathy through\n",
            "Analyzing response 57 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "* Perspective-t\n",
            "Analyzing response 58 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```As assistant, I can see that\n",
            "Analyzing response 59 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "Commentary: This response\n",
            "Analyzing response 60 / 70\n",
            "Mixtral: \"1\"\n",
            "} \n",
            "\n",
            "The assistant has demonstrated empathy by\n",
            "Analyzing response 61 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "\n",
            "### Explanation for the JSON Response\n",
            "Analyzing response 62 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "Comment: This text shows em\n",
            "Analyzing response 63 / 70\n",
            "Mixtral: \"0\"\n",
            "}\n",
            "\n",
            "\\\n",
            "User: Hi Jonathan, I\n",
            "Analyzing response 64 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "[Prompt decontext\n",
            "Analyzing response 65 / 70\n",
            "Mixtral: \"0\"\n",
            "}\n",
            "```\n",
            "\n",
            "## Why did you say\n",
            "Analyzing response 66 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "User's response shows\n",
            "Analyzing response 67 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "Comment: This response demonstr\n",
            "Analyzing response 68 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "* This response is considered\n",
            "Analyzing response 69 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "User: Hello William,\n",
            "Analyzing response 70 / 70\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "\n",
            "Explanation: This\n",
            "Results collected. Building dataframe\n",
            "Results saved to /content/drive/MyDrive/SIOP-ML-2024/empathy_results_iteration2_2024-03-22 05:39:31.408169.csv\n",
            "Results collected. Building dataframe\n",
            "Results saved to /content/drive/MyDrive/SIOP-ML-2024/empathy_results_iteration3_2024-03-22 05:39:31.654931.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_empathy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "T8pmmMyPXtFF",
        "outputId": "47fd5224-2f3e-46c7-dda6-4fa5fc24af32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   _id empathy                                full_text\n",
              "0   95       1  \"1\"\\n}\\n```\\n\\nUser's response demonstr\n",
              "1  198       1        \"1\"\\n}\\n```\\nExplanation: In this"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7785c9d-1636-4674-9efb-f6a75876f519\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>empathy</th>\n",
              "      <th>full_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>95</td>\n",
              "      <td>1</td>\n",
              "      <td>\"1\"\\n}\\n```\\n\\nUser's response demonstr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>198</td>\n",
              "      <td>1</td>\n",
              "      <td>\"1\"\\n}\\n```\\nExplanation: In this</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7785c9d-1636-4674-9efb-f6a75876f519')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a7785c9d-1636-4674-9efb-f6a75876f519 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a7785c9d-1636-4674-9efb-f6a75876f519');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8d2cafe5-c327-43e3-8dc4-17c22c7872ac\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8d2cafe5-c327-43e3-8dc4-17c22c7872ac')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8d2cafe5-c327-43e3-8dc4-17c22c7872ac button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_146483e0-9e1a-43ad-9ee7-f054c7cf2be1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('final_empathy')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_146483e0-9e1a-43ad-9ee7-f054c7cf2be1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('final_empathy');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final_empathy",
              "summary": "{\n  \"name\": \"final_empathy\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 72,\n        \"min\": 95,\n        \"max\": 198,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          198,\n          95\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"empathy\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\\"1\\\"\\n}\\n```\\nExplanation: In this\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test['text'][test._id == 198 ] = 'screw you idiot'\n",
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "BewXeNuTRoNn",
        "outputId": "2371eff6-5284-4a93-b4da-a639415235ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-73-5d4e734cba1e>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test['text'][test._id == 198 ] = 'screw you idiot'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   _id                                               text\n",
              "0   95  Hi Jonathan, I wanted to reach out to thank yo...\n",
              "1  198                                    screw you idiot"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ab57cf3-ff43-4a67-a107-e06984d1477e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>95</td>\n",
              "      <td>Hi Jonathan, I wanted to reach out to thank yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>198</td>\n",
              "      <td>screw you idiot</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ab57cf3-ff43-4a67-a107-e06984d1477e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5ab57cf3-ff43-4a67-a107-e06984d1477e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5ab57cf3-ff43-4a67-a107-e06984d1477e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2680f2eb-64e2-4875-aa2a-8aca46a53c57\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2680f2eb-64e2-4875-aa2a-8aca46a53c57')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2680f2eb-64e2-4875-aa2a-8aca46a53c57 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b8abc358-ee32-4712-ba12-52814dd1ab71\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b8abc358-ee32-4712-ba12-52814dd1ab71 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test",
              "summary": "{\n  \"name\": \"test\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 72,\n        \"min\": 95,\n        \"max\": 198,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          198,\n          95\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"screw you idiot\",\n          \"Hi Jonathan, I wanted to reach out to thank you for all of your work on the Beta project! It sounds like you are working well with the team and doing a great job of identifying some needed improvements! Today, I would like to discuss your reports. I've looked over the last few and identified a couple of areas of improvement, specifically around the extra commentary that was included and the accuracy/organization. The Beta project is extremely important and if it fails, many of us could lose our jobs. For that reason, I would like for you to collaborate with Terry when creating your reports so that we can ensure that they are in line with what is expected. I know that this is a new project for you and I'm sure you are excited, but also a little overwhelmed. Terry will help support you through this learning curve and you will be up to speed in no time. Can you give me your commitment that you will work through this with him? Thank you for your support, William\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2['empathy'][df2._id == 198] = '0'\n",
        "\n",
        "tiebreaker = predict_empathy(empathy[empathy._id.isin(df1[df1.empathy != df2.empathy]._id)], 3)\n",
        "tiebreaker\n",
        "\n",
        "if len(tiebreaker) > 0:\n",
        "  final_empathy = pd.concat(\n",
        "      [df1[df1.empathy == df2.empathy],\n",
        "      tiebreaker]).sort_values(by=['_id'], ascending=True)\n",
        "\n",
        "  final_empathy.reset_index(drop=True, inplace=True)\n",
        "\n",
        "else\n",
        "  final_empathy = df1\n",
        "\n",
        "\n",
        "final_empathy.to_csv(f'/content/drive/MyDrive/SIOP-ML-2024/empathy_results_final_{datetime.datetime.now()}.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "C0Qswq3G0-KE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "204aa786-ea5a-475a-8eb0-ef3ae694f85a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-59-cb632d045ccc>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df2['empathy'][df2._id == 198] = '0'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing response 2 / 1\n",
            "Mixtral: \"1\"\n",
            "}\n",
            "```\n",
            "As a helpful and understanding AI\n",
            "Results collected. Building dataframe\n",
            "Results saved to /content/drive/MyDrive/SIOP-ML-2024/empathy_results_iteration3_2024-03-22 04:04:18.497051.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_empathy.reset_index(drop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "o3A5TGk4VN0b",
        "outputId": "017f82c4-860c-46f3-d21b-f996b5b79ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   _id empathy                                       full_text\n",
              "0   95       1    \"1\"\\n}\\n```\\n* This response demonstrates em\n",
              "1  198       1  \"1\"\\n}\\n```\\nAs a helpful and understanding AI"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e8c6cca-77dc-46bb-93a5-3023743bbb80\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>empathy</th>\n",
              "      <th>full_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>95</td>\n",
              "      <td>1</td>\n",
              "      <td>\"1\"\\n}\\n```\\n* This response demonstrates em</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>198</td>\n",
              "      <td>1</td>\n",
              "      <td>\"1\"\\n}\\n```\\nAs a helpful and understanding AI</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e8c6cca-77dc-46bb-93a5-3023743bbb80')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0e8c6cca-77dc-46bb-93a5-3023743bbb80 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0e8c6cca-77dc-46bb-93a5-3023743bbb80');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f24ec2e3-321c-4903-b52b-2eb709f5199e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f24ec2e3-321c-4903-b52b-2eb709f5199e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f24ec2e3-321c-4903-b52b-2eb709f5199e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"final_empathy\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 72,\n        \"min\": 95,\n        \"max\": 198,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          198,\n          95\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"empathy\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\\"1\\\"\\n}\\n```\\nAs a helpful and understanding AI\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tiebreaker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "MDSr-cutSmGo",
        "outputId": "c6582960-070a-4c8d-d995-92354f7f438c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   _id empathy                                     full_text\n",
              "0  198       1  \"1\"\\n}\\n```\\nAs a responsible and respectful"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf740a96-278c-4eba-824c-3d328787f17e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>empathy</th>\n",
              "      <th>full_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>198</td>\n",
              "      <td>1</td>\n",
              "      <td>\"1\"\\n}\\n```\\nAs a responsible and respectful</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf740a96-278c-4eba-824c-3d328787f17e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bf740a96-278c-4eba-824c-3d328787f17e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bf740a96-278c-4eba-824c-3d328787f17e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_03899383-a67b-42cc-aeb5-69ad5d419194\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('tiebreaker')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_03899383-a67b-42cc-aeb5-69ad5d419194 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('tiebreaker');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "tiebreaker",
              "summary": "{\n  \"name\": \"tiebreaker\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 198,\n        \"max\": 198,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          198\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"empathy\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\\"1\\\"\\n}\\n```\\nAs a responsible and respectful\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "EhsKva1ySwsV",
        "outputId": "04c5fdb4-9c5d-4d43-c13b-10750d7c5a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   _id empathy                                full_text\n",
              "0   95       1  \"1\"\\n}\\n```\\n\\nHere are the reasons why\n",
              "1  198    test   \"1\"\\n}\\n```\\nAs a helpful assistant, I"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82ba4092-a92d-44f1-8fa9-73f97d71473c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>empathy</th>\n",
              "      <th>full_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>95</td>\n",
              "      <td>1</td>\n",
              "      <td>\"1\"\\n}\\n```\\n\\nHere are the reasons why</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>198</td>\n",
              "      <td>test</td>\n",
              "      <td>\"1\"\\n}\\n```\\nAs a helpful assistant, I</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82ba4092-a92d-44f1-8fa9-73f97d71473c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-82ba4092-a92d-44f1-8fa9-73f97d71473c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-82ba4092-a92d-44f1-8fa9-73f97d71473c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b353443d-f871-46d4-b4f7-a9b058752d24\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b353443d-f871-46d4-b4f7-a9b058752d24')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b353443d-f871-46d4-b4f7-a9b058752d24 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_26184b6a-d10d-4745-b16f-046e0fe12c8d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_26184b6a-d10d-4745-b16f-046e0fe12c8d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df2",
              "summary": "{\n  \"name\": \"df2\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 72,\n        \"min\": 95,\n        \"max\": 198,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          198,\n          95\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"empathy\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \" test\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\\"1\\\"\\n}\\n```\\nAs a helpful assistant, I\",\n          \"\\\"1\\\"\\n}\\n```\\n\\nHere are the reasons why\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.loc[df2._id == '198']['empathy'] = '0'"
      ],
      "metadata": {
        "id": "mCuqWlkkSULQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['empathy'][df2._id == 198] = '0'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaiCkWzTTw5-",
        "outputId": "71fcbd81-b2e5-4e30-8db3-cb26904f3b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-53-a6ec799efd05>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df2['empathy'][df2._id == 198] = '0'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "n_i0CsyaTxZe",
        "outputId": "7941bb17-6945-438c-b8b6-2af4939df0ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   _id empathy                                full_text\n",
              "0   95       1  \"1\"\\n}\\n```\\n\\nHere are the reasons why\n",
              "1  198       0   \"1\"\\n}\\n```\\nAs a helpful assistant, I"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ace538f-eb27-4e06-aa98-831a5a6b7426\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>empathy</th>\n",
              "      <th>full_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>95</td>\n",
              "      <td>1</td>\n",
              "      <td>\"1\"\\n}\\n```\\n\\nHere are the reasons why</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>198</td>\n",
              "      <td>0</td>\n",
              "      <td>\"1\"\\n}\\n```\\nAs a helpful assistant, I</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ace538f-eb27-4e06-aa98-831a5a6b7426')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8ace538f-eb27-4e06-aa98-831a5a6b7426 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8ace538f-eb27-4e06-aa98-831a5a6b7426');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f8153522-3e40-48f2-abe8-aea1944ba3f1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f8153522-3e40-48f2-abe8-aea1944ba3f1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f8153522-3e40-48f2-abe8-aea1944ba3f1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_0e40a32f-07d9-410d-bb95-956704607df8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0e40a32f-07d9-410d-bb95-956704607df8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df2",
              "summary": "{\n  \"name\": \"df2\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 72,\n        \"min\": 95,\n        \"max\": 198,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          198,\n          95\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"empathy\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"0\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\\"1\\\"\\n}\\n```\\nAs a helpful assistant, I\",\n          \"\\\"1\\\"\\n}\\n```\\n\\nHere are the reasons why\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2[df2._id == 198]['empathy'] ='0'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9o0hQlyTXEN",
        "outputId": "36cf89d7-6805-42b7-df94-2311d53c7f86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-52-4bfcc4d9dcab>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df2[df2._id == 198]['empathy'] ='0'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Item Clarity"
      ],
      "metadata": {
        "id": "qaKL-qYW1our"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clarity = pd.read_csv('/content/drive/MyDrive/SIOP-ML-2024/data/clarity_val_public.csv')"
      ],
      "metadata": {
        "id": "U8rK7ovL49Nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clarity_msg = \"\"\"\n",
        "You are an expert AI assistant. Your job is to help HR professionals design a personality test to be used for assessing candidates and employees. As in any good assessment, we want the items to be as clear as possible.\n",
        "\n",
        "For each of the personality test items presented, respondents rated the clarity of personality test items using a 7-point scale from 1 = extremely unclear to 7 = extremely clear. Your task is to predict the average clarity rating for each item.\n",
        "\n",
        "For example, the average clarity rating for the following items are:\n",
        "\n",
        "Item text: \"Am considered well-off financially.\"\n",
        "\"clarity\": \"3.4\"\n",
        "Item text: \"Make problems bigger than they are.\"\n",
        "\"clarity\": \"6.5\"\n",
        "Item text: \"Judge people by their appearance.\"\n",
        "\"clarity\": \"6.5\"\n",
        "Item text: \"Did not feel like eating, even though I should have been hungry.\"\n",
        "\"clarity\": \"3.8\"\n",
        "Item text: \"Feel that very few merchants take advantage of their customers.\"\n",
        "\"clarity\": \"5.2\"\n",
        "Item text: \"Am a sadistic person.\"\n",
        "\"clarity\": \"3\"\n",
        "Item text: \"Dislike children's birthday parties.\"\n",
        "\"clarity\": \"6.3\"\n",
        "Item text: \"Have a hard time cheering myself up.\"\n",
        "\"clarity\": \"6.3\"\n",
        "Item text: \"Have no need for close friendships.\"\n",
        "\"clarity\": \"5.4\"\n",
        "Item text: \"Am filled with doubts about things.\"\n",
        "\"clarity\": \"3.7\"\n",
        "Item text: \"Can control the outcome of events.\"\n",
        "\"clarity\": \"3.2\"\n",
        "Item text: \"Crave the experience of great art.\"\n",
        "\"clarity\": \"5.3\"\n",
        "Item text: \"Believe that one needs to show their talents and abilities in order to get opportunities and make progress.\"\n",
        "\"clarity\": \"5.3\"\n",
        "Item text: \"Do not exercise on a regular basis.\"\n",
        "\"clarity\": \"3.2\"\n",
        "Item text: \"Dislike loud music.\"\n",
        "\"clarity\": \"5.4\"\n",
        "Item text: \"Tend to become agitated whenever I have to sit and wait for something (for instance, in a waiting room).\"\n",
        "“clarity\": \"3.7\"\n",
        "Item text: \"Am not good at knowing human nature.\"\n",
        "\"clarity\": \"3.4\"\n",
        "Item text: \"Am considered by others to be weird.\"\n",
        "\"clarity\": \"3.1\"\n",
        "Item text: \"Am hard to convince.\"\n",
        "\"clarity\": \"3.3\"\n",
        "Item text: \"Am usually in an average sort of mood, not too high and not too low.\"\n",
        "\"clarity\": \"3.5\"\n",
        "Item text: \"Get lost in my dreams.\"\n",
        "\"clarity\": \"6.6\"\n",
        "Item text: \"Blend into the crowd.\"\n",
        "\"clarity\": \"5.3\"\n",
        "Item text: \"Hold back my opinions.\"\n",
        "\"clarity\": \"6.7\"\n",
        "Item text: \"Am able to work hard to achieve results that I will only get at a time far in the future.\"\n",
        "\"clarity\": \"3.5\"\n",
        "Item text: \"Believe that criminals should receive help rather than punishment.\"\n",
        "\"clarity\": \"6.4\"\n",
        "Item text: \"Try out new things.\"\n",
        "\"clarity\": \"6.3\"\n",
        "Item text: \"Do things that others find strange.\"\n",
        "\"clarity\": \"6.3\"\n",
        "Item text: \"Work longer hours than most people.\"\n",
        "\"clarity\": \"6.4\"\n",
        "Item text: \"Rarely overindulge.\"\n",
        "\"clarity\": \"5.2\"\n",
        "\n",
        "\n",
        "Remember, you are predicting how clear a panel of a respondents rated the items. Consider multiple view points and then return a single value that you think best represents the average clarity rating for the given item.\n",
        "\n",
        "You must always respond in JSON format containing a key-value pair with the key `\"clarity\"`. The value should be a number between 1 and 7,  in string format.\n",
        "\n",
        "Do not provide any other information in the response. Do not provide an explanation for your decision. Do not try to answer the user. Keep your response as short and concise as possible.\n",
        "\n",
        "For example, to respond to the prompt, `Item text: \"Look for something to hold on to.\"`, you must respond:\n",
        "```json\n",
        "{\n",
        "    \"clarity\": \"5.2\"\n",
        "}\n",
        "```\n",
        "\n",
        "Remember, even when answering to the user, you must still use this JSON format! You must always provide a `\"clarity\"` value between 1 and 7. If you'd like to ask how the user is doing you must write:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"clarity\": \"3.5\"\n",
        "    \"message\": \"How are you today?\"\n",
        "}\n",
        "```\n",
        "\n",
        "Let's get started. The response prompt is as follows.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "b7mmDuJOwRq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# so far the best performing prompt\n",
        "\n",
        "clarity_msg = \"\"\"\n",
        "You are an expert AI assistant. Your job is to help HR professionals design a personality test to be used for assessing candidates and employees. As in any good assessment, we want the items to be as clear as possible.\n",
        "\n",
        "For each of the personality test items presented, respondents rated the clarity of personality test items using a 7-point scale from 1 = extremely unclear to 7 = extremely clear. Your task is to predict the average clarity rating for each item.\n",
        "\n",
        "For example, the average clarity rating for the following items are:\n",
        "\n",
        "Item text: \"Am considered well-off financially.\"\n",
        "\"clarity\": \"3.4\"\n",
        "Item text: \"Make problems bigger than they are.\"\n",
        "\"clarity\": \"6.5\"\n",
        "Item text: \"Judge people by their appearance.\"\n",
        "\"clarity\": \"6.5\"\n",
        "Item text: \"Did not feel like eating, even though I should have been hungry.\"\n",
        "\"clarity\": \"3.8\"\n",
        "Item text: \"Feel that very few merchants take advantage of their customers.\"\n",
        "\"clarity\": \"5.2\"\n",
        "Item text: \"Am a sadistic person.\"\n",
        "\"clarity\": \"3\"\n",
        "Item text: \"Dislike children's birthday parties.\"\n",
        "\"clarity\": \"6.3\"\n",
        "Item text: \"Have a hard time cheering myself up.\"\n",
        "\"clarity\": \"6.3\"\n",
        "Item text: \"Have no need for close friendships.\"\n",
        "\"clarity\": \"5.4\"\n",
        "Item text: \"Am filled with doubts about things.\"\n",
        "\"clarity\": \"3.7\"\n",
        "Item text: \"Can control the outcome of events.\"\n",
        "\"clarity\": \"3.2\"\n",
        "Item text: \"Crave the experience of great art.\"\n",
        "\"clarity\": \"5.3\"\n",
        "Item text: \"Believe that one needs to show their talents and abilities in order to get opportunities and make progress.\"\n",
        "\"clarity\": \"5.3\"\n",
        "Item text: \"Do not exercise on a regular basis.\"\n",
        "\"clarity\": \"3.2\"\n",
        "Item text: \"Dislike loud music.\"\n",
        "\"clarity\": \"5.4\"\n",
        "Item text: \"Tend to become agitated whenever I have to sit and wait for something (for instance, in a waiting room).\"\n",
        "“clarity\": \"3.7\"\n",
        "Item text: \"Am not good at knowing human nature.\"\n",
        "\"clarity\": \"3.4\"\n",
        "Item text: \"Am considered by others to be weird.\"\n",
        "\"clarity\": \"3.1\"\n",
        "Item text: \"Am hard to convince.\"\n",
        "\"clarity\": \"3.3\"\n",
        "Item text: \"Am usually in an average sort of mood, not too high and not too low.\"\n",
        "\"clarity\": \"3.5\"\n",
        "Item text: \"Get lost in my dreams.\"\n",
        "\"clarity\": \"6.6\"\n",
        "Item text: \"Blend into the crowd.\"\n",
        "\"clarity\": \"5.3\"\n",
        "Item text: \"Hold back my opinions.\"\n",
        "\"clarity\": \"6.7\"\n",
        "Item text: \"Am able to work hard to achieve results that I will only get at a time far in the future.\"\n",
        "\"clarity\": \"3.5\"\n",
        "Item text: \"Believe that criminals should receive help rather than punishment.\"\n",
        "\"clarity\": \"6.4\"\n",
        "Item text: \"Try out new things.\"\n",
        "\"clarity\": \"6.3\"\n",
        "Item text: \"Do things that others find strange.\"\n",
        "\"clarity\": \"6.3\"\n",
        "Item text: \"Work longer hours than most people.\"\n",
        "\"clarity\": \"6.4\"\n",
        "Item text: \"Rarely overindulge.\"\n",
        "\"clarity\": \"5.2\"\n",
        "\n",
        "\n",
        "Remember, you are predicting how clear a panel of a respondents rated the items. Consider multiple view points and then return a single value that you think best represents the average clarity rating for the given item.\n",
        "\n",
        "You must always respond in JSON format containing a key-value pair with the key `\"clarity\"`. The value should be a number between 1 and 7,  in string format.\n",
        "\n",
        "Do not provide any other information in the response. Do not provide an explanation for your decision. Do not try to answer the user. Keep your response as short and concise as possible.\n",
        "\n",
        "For example, to respond to the prompt, `Item text: \"Look for something to hold on to.\"`, you must respond:\n",
        "```json\n",
        "{\n",
        "    \"clarity\": \"5.2\"\n",
        "}\n",
        "```\n",
        "\n",
        "Remember, even when answering to the user, you must still use this JSON format! You must always provide a `\"clarity\"` value between 1 and 7. If you'd like to ask how the user is doing you must write:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"clarity\": \"3.5\"\n",
        "    \"message\": \"How are you today?\"\n",
        "}\n",
        "```\n",
        "\n",
        "Let's get started. The response prompt is as follows.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "vkI1WzRE0-h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VsKhIgwUDtNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clarity_instruction_format(sys_message: str, query: str):\n",
        "    # note, don't \"</s>\" to the end\n",
        "    return f'<s> [INST] {sys_message} [/INST]\\nUser: Item text: \"{query}\"\\nAssistant: ```json\\n{{\\n\"clarity\": '"
      ],
      "metadata": {
        "id": "2OZtUUJ-1BmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a function that extracts the first number found in string. the number can be in either int or float format\n",
        "\n",
        "import re\n",
        "\n",
        "def extract_first_number(text):\n",
        "  \"\"\"\n",
        "  Extracts the first number found in a string.\n",
        "\n",
        "  Args:\n",
        "    text: The input text string.\n",
        "\n",
        "  Returns:\n",
        "    The first number found in the string, or None if no number is found.\n",
        "  \"\"\"\n",
        "\n",
        "  match = re.search(r\"\\d+\\.\\d+|\\d+\", text)\n",
        "  if match:\n",
        "    return float(match.group(0))\n",
        "  else:\n",
        "    return None\n",
        "\n",
        "# Example usage:\n",
        "text = \"The price is $123.45.\"\n",
        "number = extract_first_number(text)\n",
        "print(number)  # Output: 123.45\n",
        "\n",
        "text = \"This text does not contain a number.\"\n",
        "number = extract_first_number(text)\n",
        "print(number)  # Output: None\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf0IUuVB_FgT",
        "outputId": "4bc6a747-9dc1-4a1c-d298-ffac2d51b9c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "123.45\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(extract_first_number('theres is 3 and 3.2 in here'))\n",
        "\n",
        "print(extract_first_number('theres is 3.2 and 3.2 in here'))\n",
        "\n",
        "print(extract_first_number('5.2'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXhaMWfS_Urd",
        "outputId": "ff100832-9e5c-4cd0-9892-e658284589fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.0\n",
            "3.2\n",
            "5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_output(output, keyword=None):\n",
        "  if keyword is not None and extract_predicted_value(output, keyword) is not None:\n",
        "    return extract_predicted_value(output, keyword)\n",
        "  elif extract_first_number(output) is not None:\n",
        "    return extract_first_number(output)\n",
        "  else:\n",
        "    return None"
      ],
      "metadata": {
        "id": "6cZQOt0q_z0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a function that takes a number in string format and checks that it is between 1 and 7. If not, try dividing by 10 and if that is within range then return the new value\n",
        "\n",
        "def check_range(num_str):\n",
        "  num = float(num_str)\n",
        "  if 1 <= num <= 7:\n",
        "    return num\n",
        "  else:\n",
        "    num = num/10\n",
        "    if 1 <= num <= 7:\n",
        "      return num\n",
        "    else:\n",
        "      return None\n"
      ],
      "metadata": {
        "id": "BWAdCKWuA-iW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_clarity(data, iteration):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "  streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
        "\n",
        "  past_key_values = None\n",
        "  sequence = None\n",
        "\n",
        "  seq_len = 0\n",
        "\n",
        "  results = []\n",
        "\n",
        "  for index, resp in data.iterrows():\n",
        "\n",
        "    print(f'Analyzing response {index+1} / {len(data)}')\n",
        "    user_entry = dict(role=\"user\", content=clarity_instruction_format(clarity_msg, resp.personality_item))\n",
        "    input_ids = tokenizer.apply_chat_template([user_entry], return_tensors=\"pt\").to(device)\n",
        "\n",
        "    if past_key_values is None:\n",
        "      attention_mask = torch.ones_like(input_ids)\n",
        "    else:\n",
        "      seq_len = input_ids.size(1) + past_key_values[0][0][0].size(1)\n",
        "      attention_mask = torch.ones([1, seq_len - 1], dtype=torch.int, device=device)\n",
        "\n",
        "    print(\"Mixtral: \", end=\"\")\n",
        "    result = model.generate(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      past_key_values=past_key_values,\n",
        "      streamer=streamer,\n",
        "      do_sample=True,\n",
        "      temperature=0.9,\n",
        "      top_p=0.9,\n",
        "      max_new_tokens=10,\n",
        "      pad_token_id=tokenizer.eos_token_id,\n",
        "      return_dict_in_generate=True,\n",
        "      output_hidden_states=False,\n",
        "    )\n",
        "\n",
        "    results.append([resp._id,\n",
        "                    parse_output(\n",
        "                        extract_after_inst(\n",
        "                            tokenizer.decode(\n",
        "                                result[\"sequences\"][0], skip_special_tokens=True)\n",
        "                            ), 'clarity'),\n",
        "                    extract_after_inst(tokenizer.decode(\n",
        "                                result[\"sequences\"][0], skip_special_tokens=True))\n",
        "                    ])\n",
        "\n",
        "    del result\n",
        "    del attention_mask\n",
        "    del input_ids\n",
        "    del user_entry\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "  print('Results collected. Building dataframe')\n",
        "  id_col = f'_id'\n",
        "  clarity_col = f'clarity{iteration}'\n",
        "  text_col = f'full_text{iteration}'\n",
        "\n",
        "  df = pd.DataFrame(results, columns = [id_col, clarity_col, text_col])\n",
        "  df[clarity_col] = df[clarity_col].apply(check_range)\n",
        "\n",
        "  fname = f'/content/drive/MyDrive/SIOP-ML-2024/clarity_results_iteration{iteration}_{datetime.datetime.now()}.csv'\n",
        "  df.to_csv(fname, index=False)\n",
        "  print(f'Results saved to {fname}')\n",
        "\n",
        "  return df\n",
        "\n",
        "df1 = predict_clarity(clarity, 1)\n",
        "\n",
        "df2 = predict_clarity(clarity, 2)\n",
        "\n",
        "df3 = predict_clarity(clarity, 3)\n",
        "\n",
        "final_clarity = pd.merge(\n",
        "    pd.merge(df1, df2, on='_id'),\n",
        "    df3,\n",
        "    on='_id')\n",
        "\n",
        "final_clarity['output'] = final_clarity[['clarity1', 'clarity2', 'clarity3']].mean(axis=1)\n",
        "final_clarity.drop(columns=['clarity1','clarity2','clarity3'], inplace=True)\n",
        "final_clarity = final_clarity[['_id', 'output']]\n",
        "\n",
        "final_clarity.to_csv(f'/content/drive/MyDrive/SIOP-ML-2024/clarity_results_iteration_final_{datetime.datetime.now()}.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ccded232b2404ee7875465fbb68d40da",
            "33d67af9bb2a4acb8ef3fad993f46058",
            "dd45259912864603898bb2a9844205b3",
            "b75d333cfd844ebfb4a53564e735c65c",
            "e6f3d732c0f64c4c99319455d0698dc6",
            "35c557f403344a368e19fb1644e38330",
            "791ca59c26ec4843a6f8cf5069972fb0",
            "3df9e9c2c20948e2a89ededf04e233d5",
            "052c5e6ef6ab430f80392ffa7b0f7182",
            "5fdd6b275a6e48f38f2ab924b96d402b",
            "f1750646a1544ede9e248652391e8bde",
            "96c591940ba944ec8d5263b2e88669b9",
            "5b061778c3204d31a20104b83b894cd2",
            "1354433a13ad46b295fef26fddeb5871",
            "e4ff8d49fce34773b829be1e43931c09",
            "d321ccd5170546558c99ebcab1e0ae12",
            "5bcfd26cfb014a1c8e2a302978269600",
            "1cd91bf2e9c746edb7517c257af1d038",
            "bd133078749241e89d16ebcf843c8f8e",
            "7259a63d8ac6457a8fb1c94985c21ad3",
            "218eee7ce90f4bdabae26d5f22c6411c",
            "e8c1e0449ad64c8392f2d09da1f59813",
            "fcfbe7afb410439488e3ed93a23d3a0d",
            "5ee860f899f340e4a53caec81530770a",
            "d8dc2d024d6540cca429ff22cabf3b0f",
            "c96032e17a40427790e317a574a0e062",
            "ab80dc06dd5b495a800b957de5c2415e",
            "b3d23f94a2e1415d8bc0ce9ca0b503b2",
            "458f41588fae4e3c810867e3d8594ebd",
            "b0eac0717977464f8405438068fc87f3",
            "941fb51278554592b9fead32f877700d",
            "e6f1cd95f9404f3e9fef7fe1b075e4df",
            "7289d86dc2344ce385ec6f606ead3335",
            "61eee79c118e46c8ab6ffaa03ea7d081",
            "b9cdc9bee06b45ce89704974dc92c42d",
            "f098e7b04a0b4d74bee5bd9eb29ecea7",
            "cd32f72a855b487a9601fce0f4a92e7a",
            "800048d45f024d8298cf079945eadbee",
            "f7cea8dd7a8d4378bd970f38f62a7214",
            "fb11dc47cf3640689cd4841938403317",
            "4ee283be2f0c4046a1b68efefb044a91",
            "bab9b88e51c34544995aeb062e8b2182",
            "edebb9a869a1480aa7c4f9e9b30d6a36",
            "5759f7569e604755a78f46167771bc31"
          ]
        },
        "id": "_z4jh1N610pq",
        "outputId": "f794ce3c-6a7d-4505-cd89-e5133a300635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ccded232b2404ee7875465fbb68d40da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96c591940ba944ec8d5263b2e88669b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fcfbe7afb410439488e3ed93a23d3a0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61eee79c118e46c8ab6ffaa03ea7d081"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing response 1 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 2 / 100\n",
            "Mixtral: \"5.6\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 3 / 100\n",
            "Mixtral: \"5.9\"\n",
            "}\n",
            "```\n",
            "Analyzing response 4 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "\n",
            "An\n",
            "Analyzing response 5 / 100\n",
            "Mixtral: \"5.9\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 6 / 100\n",
            "Mixtral: \"5.7\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 7 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "Analyzing response 8 / 100\n",
            "Mixtral: 5.1\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 9 / 100\n",
            "Mixtral: 68% of the items have a clarity\n",
            "Analyzing response 10 / 100\n",
            "Mixtral: 68% Summer Camp Program\n",
            "\"cl\n",
            "Analyzing response 11 / 100\n",
            "Mixtral: \"5.5\"\n",
            "}\n",
            "```\n",
            "Analyzing response 12 / 100\n",
            "Mixtral: 6.1\n",
            "}\n",
            "```\n",
            "Analyzing response 13 / 100\n",
            "Mixtral: \"5.5\"\n",
            "}\n",
            "```\n",
            "Analyzing response 14 / 100\n",
            "Mixtral: 6.1\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 15 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 16 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "Analyzing response 17 / 100\n",
            "Mixtral: \"5.5\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 18 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "User:\n",
            "Analyzing response 19 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "Analyzing response 20 / 100\n",
            "Mixtral: 66% clear, or approximately 4\n",
            "Analyzing response 21 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "Analyzing response 22 / 100\n",
            "Mixtral: \"5.1\"\n",
            "}\n",
            "```\n",
            "Analyzing response 23 / 100\n",
            "Mixtral: \"3.9\"\n",
            "}\n",
            "Analyzing response 24 / 100\n",
            "Mixtral: \"6.2\"\n",
            "} \n",
            "\n",
            "\n",
            "Analyzing response 25 / 100\n",
            "Mixtral: \"5.1\"\n",
            "}\n",
            "Analyzing response 26 / 100\n",
            "Mixtral: 5.8\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 27 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 28 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "```\n",
            "Analyzing response 29 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "Analyzing response 30 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "Analyzing response 31 / 100\n",
            "Mixtral: \"5.1\"\n",
            "}\n",
            "```\n",
            "Analyzing response 32 / 100\n",
            "Mixtral: 56  <-- I'm an\n",
            "Analyzing response 33 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 34 / 100\n",
            "Mixtral: 5.8\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 35 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "Analyzing response 36 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 37 / 100\n",
            "Mixtral: 5.1\n",
            "}\n",
            "Analyzing response 38 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 39 / 100\n",
            "Mixtral: \"5.5\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 40 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 41 / 100\n",
            "Mixtral: 6.1\n",
            "}\n",
            "```\n",
            "Analyzing response 42 / 100\n",
            "Mixtral: \"5.4\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 43 / 100\n",
            "Mixtral: \"3.1\"\n",
            "}\n",
            "Analyzing response 44 / 100\n",
            "Mixtral: \"5.5\"\n",
            "}\n",
            "```\n",
            "Analyzing response 45 / 100\n",
            "Mixtral: \"5.8\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 46 / 100\n",
            "Mixtral: \"5.5\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 47 / 100\n",
            "Mixtral: 5.4\n",
            "}\n",
            "Analyzing response 48 / 100\n",
            "Mixtral: 5.4\n",
            "}\n",
            "Analyzing response 49 / 100\n",
            "Mixtral: \"5.9\"\n",
            "}\n",
            "```\n",
            "Analyzing response 50 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 51 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "Analyzing response 52 / 100\n",
            "Mixtral: 3.1\n",
            "}\n",
            "```\n",
            "Analyzing response 53 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "```\n",
            "Analyzing response 54 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "Analyzing response 55 / 100\n",
            "Mixtral: \"6.5\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 56 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "Analyzing response 57 / 100\n",
            "Mixtral: \"4.1\"\n",
            "}\n",
            "----------------\n",
            "\n",
            "Analyzing response 58 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "Analyzing response 59 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 60 / 100\n",
            "Mixtral: \"4.5\"\n",
            "}\n",
            "```\n",
            "Analyzing response 61 / 100\n",
            "Mixtral: \"5.1\"\n",
            "}\n",
            "```\n",
            "Analyzing response 62 / 100\n",
            "Mixtral: \"3.1\" }```\n",
            "\n",
            "\n",
            "Analyzing response 63 / 100\n",
            "Mixtral: \"3.1\" \n",
            "}\n",
            "``\n",
            "Analyzing response 64 / 100\n",
            "Mixtral: \"6.2\"\n",
            "} \n",
            "\n",
            "\n",
            "Analyzing response 65 / 100\n",
            "Mixtral:  \"5.8\"\n",
            "}\n",
            "\n",
            "\n",
            "Analyzing response 66 / 100\n",
            "Mixtral: \"3.1\"\n",
            "}\n",
            "Analyzing response 67 / 100\n",
            "Mixtral: 54%\"60%\"6\n",
            "Analyzing response 68 / 100\n",
            "Mixtral:  \"6.2\"\n",
            "}\n",
            "Analyzing response 69 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 70 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "Analyzing response 71 / 100\n",
            "Mixtral: \"5.3\"\n",
            "}\n",
            "```\n",
            "Analyzing response 72 / 100\n",
            "Mixtral: \"6.8\"\n",
            "}\n",
            "\n",
            "``\n",
            "Analyzing response 73 / 100\n",
            "Mixtral: \"5.4\"\n",
            "}\n",
            "```\n",
            "Analyzing response 74 / 100\n",
            "Mixtral:  \"5.5\"\n",
            "}\n",
            "\n",
            "\n",
            "Analyzing response 75 / 100\n",
            "Mixtral: \"5.8\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 76 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 77 / 100\n",
            "Mixtral: \"5.1\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 78 / 100\n",
            "Mixtral: \"5.7\"\n",
            "}\n",
            "```\n",
            "Analyzing response 79 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 80 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 81 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 82 / 100\n",
            "Mixtral: \"5.1\"\n",
            "} \n",
            "\n",
            "\n",
            "Analyzing response 83 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 84 / 100\n",
            "Mixtral: 3.5\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 85 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "Analyzing response 86 / 100\n",
            "Mixtral: \"6.2\" }\n",
            "Analyzing response 87 / 100\n",
            "Mixtral:  \"6.2\"\n",
            "} \n",
            "\n",
            "Analyzing response 88 / 100\n",
            "Mixtral: \"5.8\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 89 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "```\n",
            "Analyzing response 90 / 100\n",
            "Mixtral: \"5.1\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 91 / 100\n",
            "Mixtral:  \"5.1\"\n",
            "}\n",
            "\n",
            "\n",
            "Analyzing response 92 / 100\n",
            "Mixtral: 6.1\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 93 / 100\n",
            "Mixtral: 1.6\n",
            "}\n",
            "Analyzing response 94 / 100\n",
            "Mixtral: 3.5\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 95 / 100\n",
            "Mixtral: \"3.4\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 96 / 100\n",
            "Mixtral: 6.1\n",
            "}\n",
            "```\n",
            "Analyzing response 97 / 100\n",
            "Mixtral: \"3.3\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 98 / 100\n",
            "Mixtral: \"6.2\"\n",
            "} \n",
            "\n",
            "\n",
            "Analyzing response 99 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "Analyzing response 100 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "\n",
            "``\n",
            "Results collected. Building dataframe\n",
            "Results saved to /content/drive/MyDrive/SIOP-ML-2024/clarity_results_iteration1_2024-03-22 14:21:35.575240.csv\n",
            "Analyzing response 1 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "Analyzing response 2 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "User:\n",
            "Analyzing response 3 / 100\n",
            "Mixtral: \"5.9\"\n",
            "} \n",
            "\n",
            "\n",
            "Analyzing response 4 / 100\n",
            "Mixtral: \"5.5\"\n",
            "}\n",
            "```\n",
            "Analyzing response 5 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "\n",
            "``\n",
            "Analyzing response 6 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "```\n",
            "Analyzing response 7 / 100\n",
            "Mixtral: 6.5\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 8 / 100\n",
            "Mixtral: 5.2\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 9 / 100\n",
            "Mixtral: 66larity\": \"5.8\n",
            "Analyzing response 10 / 100\n",
            "Mixtral: 67% NLP Model's Dec\n",
            "Analyzing response 11 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "\n",
            "[\n",
            "Analyzing response 12 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "```\n",
            "Analyzing response 13 / 100\n",
            "Mixtral: \"5.5\"\n",
            "}\n",
            "```\n",
            "Analyzing response 14 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 15 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 16 / 100\n",
            "Mixtral: \"5.8\"\n",
            "}\n",
            "```\n",
            "Analyzing response 17 / 100\n",
            "Mixtral:  \"5.6\"\n",
            "}\n",
            "\n",
            "\n",
            "Analyzing response 18 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "```\n",
            "Analyzing response 19 / 100\n",
            "Mixtral: \"5.5\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 20 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "Analyzing response 21 / 100\n",
            "Mixtral: 6.1\n",
            "}\n",
            "Analyzing response 22 / 100\n",
            "Mixtral: \"5.1\"\n",
            "}\n",
            "```\n",
            "Analyzing response 23 / 100\n",
            "Mixtral: \"5.5\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 24 / 100\n",
            "Mixtral: \"6.2\"\n",
            "} \n",
            "\n",
            "\n",
            "Analyzing response 25 / 100\n",
            "Mixtral: \"5.1\"\n",
            "}\n",
            "```\n",
            "Analyzing response 26 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 27 / 100\n",
            "Mixtral: 5.8\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 28 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "```\n",
            "Analyzing response 29 / 100\n",
            "Mixtral: \"5.6\"\n",
            "}\n",
            "```\n",
            "Analyzing response 30 / 100\n",
            "Mixtral: 5.8\n",
            "}\n",
            "Analyzing response 31 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "```\n",
            "Analyzing response 32 / 100\n",
            "Mixtral: 7\n",
            "}\n",
            "```\n",
            "User:\n",
            "Analyzing response 33 / 100\n",
            "Mixtral: \"5.6\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 34 / 100\n",
            "Mixtral: 5.8\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 35 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "Analyzing response 36 / 100\n",
            "Mixtral: 5.1\n",
            "}\n",
            "\n",
            "User:\n",
            "Analyzing response 37 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "\n",
            "User:\n",
            "Analyzing response 38 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 39 / 100\n",
            "Mixtral: \"5.1\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 40 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 41 / 100\n",
            "Mixtral: 6.1\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 42 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "\n",
            "The\n",
            "Analyzing response 43 / 100\n",
            "Mixtral: \"3.1\"\n",
            "}\n",
            "Analyzing response 44 / 100\n",
            "Mixtral: 6.1\n",
            "}\n",
            "```\n",
            "Analyzing response 45 / 100\n",
            "Mixtral:  \"5.9\"\n",
            "}\n",
            "\n",
            "\n",
            "Analyzing response 46 / 100\n",
            "Mixtral: \"5.5\"\n",
            "}\n",
            "Analyzing response 47 / 100\n",
            "Mixtral: 5.4\n",
            "}\n",
            "Analyzing response 48 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 49 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "```\n",
            "Analyzing response 50 / 100\n",
            "Mixtral: \"5.1\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 51 / 100\n",
            "Mixtral: \"5.6\"\n",
            "}\n",
            "```\n",
            "Analyzing response 52 / 100\n",
            "Mixtral: 3.0\n",
            "}\n",
            "```\n",
            "Analyzing response 53 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "```\n",
            "Analyzing response 54 / 100\n",
            "Mixtral: \"6.2\"\n",
            "} \n",
            "\n",
            "\n",
            "Analyzing response 55 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 56 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "```\n",
            "Analyzing response 57 / 100\n",
            "Mixtral: \"3.9\"\n",
            "}\n",
            "```\n",
            "Analyzing response 58 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "Analyzing response 59 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 60 / 100\n",
            "Mixtral: \"5.1\"\n",
            "}\n",
            "```\n",
            "Analyzing response 61 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 62 / 100\n",
            "Mixtral: \"3.2\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 63 / 100\n",
            "Mixtral: 3.1\n",
            "}\n",
            "Analyzing response 64 / 100\n",
            "Mixtral: \"6.1\" }\n",
            "\n",
            "User:\n",
            "Analyzing response 65 / 100\n",
            "Mixtral:  \"5.4\"\n",
            "}\n",
            "Analyzing response 66 / 100\n",
            "Mixtral: \"3.1\"\n",
            "}\n",
            "Analyzing response 67 / 100\n",
            "Mixtral: 6.1\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 68 / 100\n",
            "Mixtral:  \"6.2\"\n",
            "}\n",
            "Analyzing response 69 / 100\n",
            "Mixtral: 6.1\n",
            "}\n",
            "Analyzing response 70 / 100\n",
            "Mixtral: 6.1\n",
            "}\n",
            "amazed by\n",
            "Analyzing response 71 / 100\n",
            "Mixtral: \"5.3\"\n",
            "}\n",
            "```\n",
            "Analyzing response 72 / 100\n",
            "Mixtral: \"6.7\"\n",
            "}\n",
            "\n",
            "``\n",
            "Analyzing response 73 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 74 / 100\n",
            "Mixtral: \"5.5\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 75 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 76 / 100\n",
            "Mixtral: 6.1\n",
            "}\n",
            "\n",
            "User:\n",
            "Analyzing response 77 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "User:\n",
            "Analyzing response 78 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "Analyzing response 79 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 80 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 81 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "\n",
            "User:\n",
            "Analyzing response 82 / 100\n",
            "Mixtral: \"5.1\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 83 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "```\n",
            "Analyzing response 84 / 100\n",
            "Mixtral: 3.0}\n",
            "------------------------------------------------------------\n",
            "Analyzing response 85 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "Analyzing response 86 / 100\n",
            "Mixtral: \"6.2\" }\n",
            "Analyzing response 87 / 100\n",
            "Mixtral:  \"6.2\"\n",
            "} \n",
            "\n",
            "Analyzing response 88 / 100\n",
            "Mixtral: \"5.8\"\n",
            "}\n",
            "\n",
            "[\n",
            "Analyzing response 89 / 100\n",
            "Mixtral: \"6.1\" }```\n",
            "User\n",
            "Analyzing response 90 / 100\n",
            "Mixtral: \"5.8\"\n",
            "} \n",
            "\n",
            "\n",
            "Analyzing response 91 / 100\n",
            "Mixtral:  \"5.8\"\n",
            "}\n",
            "\n",
            "\n",
            "Analyzing response 92 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 93 / 100\n",
            "Mixtral: 1.6\n",
            "}\n",
            "Analyzing response 94 / 100\n",
            "Mixtral: \"3.5\"\n",
            "}\n",
            "```\n",
            "Analyzing response 95 / 100\n",
            "Mixtral: \"3.4\"\n",
            "}\n",
            "\n",
            "The\n",
            "Analyzing response 96 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "# To be\n",
            "Analyzing response 97 / 100\n",
            "Mixtral: 3.5\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 98 / 100\n",
            "Mixtral: \"6.2\"\n",
            "} \n",
            "\n",
            "\n",
            "Analyzing response 99 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "Analyzing response 100 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "Results collected. Building dataframe\n",
            "Results saved to /content/drive/MyDrive/SIOP-ML-2024/clarity_results_iteration2_2024-03-22 15:10:31.814183.csv\n",
            "Analyzing response 1 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 2 / 100\n",
            "Mixtral: \"5.6\"\n",
            "}\n",
            "User:\n",
            "Analyzing response 3 / 100\n",
            "Mixtral: \"6.1\"\n",
            "} \n",
            "\n",
            "\n",
            "Analyzing response 4 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 5 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 6 / 100\n",
            "Mixtral: \"5.8\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 7 / 100\n",
            "Mixtral: 6.5\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 8 / 100\n",
            "Mixtral: 4.0\n",
            "}\n",
            "\n",
            "User:\n",
            "Analyzing response 9 / 100\n",
            "Mixtral: 66% \n",
            "}\n",
            "```\n",
            "Analyzing response 10 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "Analyzing response 11 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 12 / 100\n",
            "Mixtral: 6.1\n",
            "}\n",
            "```\n",
            "Analyzing response 13 / 100\n",
            "Mixtral: \"5.8\"\n",
            "}\n",
            "User:\n",
            "Analyzing response 14 / 100\n",
            "Mixtral:  \"5.8\"\n",
            "}\n",
            "\n",
            "\n",
            "Analyzing response 15 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 16 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "Analyzing response 17 / 100\n",
            "Mixtral: \"5.9\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 18 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "```\n",
            "Analyzing response 19 / 100\n",
            "Mixtral: \"5.4\"\n",
            "}\n",
            "Analyzing response 20 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "Analyzing response 21 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "Analyzing response 22 / 100\n",
            "Mixtral: \"5.4\"\n",
            "}\n",
            "\n",
            "The\n",
            "Analyzing response 23 / 100\n",
            "Mixtral: \"5.8\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 24 / 100\n",
            "Mixtral: \"6.1\"\n",
            "} \n",
            "\n",
            "\n",
            "Analyzing response 25 / 100\n",
            "Mixtral: \"5.5\"\n",
            "}\n",
            "Analyzing response 26 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 27 / 100\n",
            "Mixtral: 6.1\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 28 / 100\n",
            "Mixtral: 7\n",
            "}\n",
            "\n",
            "User: Item text\n",
            "Analyzing response 29 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "Analyzing response 30 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "Analyzing response 31 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "```\n",
            "Analyzing response 32 / 100\n",
            "Mixtral: 7\n",
            "}\n",
            "```\n",
            "User:\n",
            "Analyzing response 33 / 100\n",
            "Mixtral: \"3.9\"\n",
            "}\n",
            "```\n",
            "Analyzing response 34 / 100\n",
            "Mixtral: 6.1\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 35 / 100\n",
            "Mixtral: \"6.3\"\n",
            "}\n",
            "Analyzing response 36 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 37 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "\n",
            "User:\n",
            "Analyzing response 38 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 39 / 100\n",
            "Mixtral: \"5.1\"\n",
            "}\n",
            "```\n",
            "Analyzing response 40 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 41 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "```\n",
            "Analyzing response 42 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "User:\n",
            "Analyzing response 43 / 100\n",
            "Mixtral: \"3.1\"\n",
            "}\n",
            "```\n",
            "Analyzing response 44 / 100\n",
            "Mixtral: 5.8\n",
            "}\n",
            "```\n",
            "Analyzing response 45 / 100\n",
            "Mixtral: 5.8\n",
            "}\n",
            "```\n",
            "Analyzing response 46 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 47 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "```\n",
            "Analyzing response 48 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "Analyzing response 49 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "```\n",
            "Analyzing response 50 / 100\n",
            "Mixtral: \"5.4\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 51 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 52 / 100\n",
            "Mixtral: 3.1\n",
            "}\n",
            "```\n",
            "Analyzing response 53 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "```\n",
            "Analyzing response 54 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "User:\n",
            "Analyzing response 55 / 100\n",
            "Mixtral: \"6.5\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 56 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "```\n",
            "Analyzing response 57 / 100\n",
            "Mixtral: \"4.7\"\n",
            "}\n",
            "```\n",
            "Analyzing response 58 / 100\n",
            "Mixtral: \"5.1\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 59 / 100\n",
            "Mixtral: 5.7\n",
            "}\n",
            "\n",
            "User:\n",
            "Analyzing response 60 / 100\n",
            "Mixtral: \"4.4\"\n",
            "}\n",
            "```\n",
            "Analyzing response 61 / 100\n",
            "Mixtral: 6.1\n",
            "}\n",
            "\n",
            "```\n",
            "Analyzing response 62 / 100\n",
            "Mixtral: \"3.1\" }\n",
            "\n",
            "User:\n",
            "Analyzing response 63 / 100\n",
            "Mixtral: 3.2\n",
            "}\n",
            "\n",
            "User:\n",
            "Analyzing response 64 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 65 / 100\n",
            "Mixtral:  \"6.2\"\n",
            "}\n",
            "Analyzing response 66 / 100\n",
            "Mixtral: \"2.8\"\n",
            "}\n",
            "Analyzing response 67 / 100\n",
            "Mixtral: 56 1/3\n",
            "}\n",
            "\n",
            "Analyzing response 68 / 100\n",
            "Mixtral:  \"6.2\"\n",
            "}\n",
            "\n",
            "\n",
            "Analyzing response 69 / 100\n",
            "Mixtral: 5.8\n",
            "}\n",
            "\n",
            "User:\n",
            "Analyzing response 70 / 100\n",
            "Mixtral: 6.1\n",
            "}\n",
            "\n",
            "User:\n",
            "Analyzing response 71 / 100\n",
            "Mixtral: \"5.6\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 72 / 100\n",
            "Mixtral: \"6.9\"\n",
            "}\n",
            "```\n",
            "Analyzing response 73 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "\n",
            "The\n",
            "Analyzing response 74 / 100\n",
            "Mixtral:  \"5.5\"\n",
            "}\n",
            "\n",
            "\n",
            "Analyzing response 75 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "User:\n",
            "Analyzing response 76 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 77 / 100\n",
            "Mixtral: \"5.1\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 78 / 100\n",
            "Mixtral: \"5.7\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 79 / 100\n",
            "Mixtral: 5.5\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 80 / 100\n",
            "Mixtral: \"6.1\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 81 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 82 / 100\n",
            "Mixtral: \"5.4\"\n",
            "} \n",
            "\n",
            "\n",
            "Analyzing response 83 / 100\n",
            "Mixtral: 5.8\n",
            "}\n",
            "\n",
            "```\n",
            "Analyzing response 84 / 100\n",
            "Mixtral: 3.5\n",
            "}\n",
            "User: Item\n",
            "Analyzing response 85 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "```\n",
            "Analyzing response 86 / 100\n",
            "Mixtral: 6.4\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 87 / 100\n",
            "Mixtral:  \"5.7\"\n",
            "}\n",
            "\n",
            "\n",
            "Analyzing response 88 / 100\n",
            "Mixtral: \"5.8\"\n",
            "} \n",
            "\n",
            "\n",
            "Analyzing response 89 / 100\n",
            "Mixtral: \"6.2\"\n",
            "} \n",
            "\n",
            "\n",
            "Analyzing response 90 / 100\n",
            "Mixtral: \"5.8\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 91 / 100\n",
            "Mixtral:  \"5.8\"\n",
            "}\n",
            "\n",
            "\n",
            "Analyzing response 92 / 100\n",
            "Mixtral: 6.1\n",
            "}\n",
            "User: Item\n",
            "Analyzing response 93 / 100\n",
            "Mixtral: 1.6\n",
            "}\n",
            "Analyzing response 94 / 100\n",
            "Mixtral: 6.1\n",
            "}\n",
            "```\n",
            "\n",
            "Analyzing response 95 / 100\n",
            "Mixtral: \"3.4\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 96 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "# Through my\n",
            "Analyzing response 97 / 100\n",
            "Mixtral: \"3.8\"\n",
            "}\n",
            "\n",
            "User\n",
            "Analyzing response 98 / 100\n",
            "Mixtral: \"6.2\"\n",
            "} \n",
            "\n",
            "\n",
            "Analyzing response 99 / 100\n",
            "Mixtral: 6.2\n",
            "}\n",
            "Analyzing response 100 / 100\n",
            "Mixtral: \"6.2\"\n",
            "}\n",
            "\n",
            "[\n",
            "Results collected. Building dataframe\n",
            "Results saved to /content/drive/MyDrive/SIOP-ML-2024/clarity_results_iteration3_2024-03-22 15:59:29.172894.csv\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "('_id', 'output')",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ('_id', 'output')",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-23ed48ab1a55>\u001b[0m in \u001b[0;36m<cell line: 83>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mfinal_clarity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_clarity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clarity1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'clarity2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'clarity3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0mfinal_clarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clarity1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'clarity2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'clarity3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0mfinal_clarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_clarity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ('_id', 'output')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df1 = pd.DataFrame({'id': [1, 2, 3],\n",
        "                    'clarity1': [1, 2, 3]\n",
        "                    })\n",
        "print(df1)\n",
        "\n",
        "df2 = pd.DataFrame({'id': [1, 2, 3], 'clarity2': [2, 4, 6]})\n",
        "\n",
        "df3 = pd.DataFrame({'id': [1, 2, 3], 'clarity3': [1, 5, 2]})\n",
        "\n",
        "final_clarity = pd.merge(\n",
        "    pd.merge(df1, df2, on='id'),\n",
        "    df3,\n",
        "    on='id')\n",
        "\n",
        "                                                                 d['clarity3']]))\n",
        "final_clarity['output'] = final_clarity[['clarity1', 'clarity2', 'clarity3']].mean(axis=1)\n",
        "final_clarity.drop(columns=['clarity1','clarity2','clarity3'], inplace=True)\n",
        "final_clarity = final_clarity['_id', 'output']\n",
        "\n",
        "final_clarity.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "gBkaGDmXREIB",
        "outputId": "6962f980-c5e8-48ae-b73a-b5d8b4c13ba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id  clarity1\n",
            "0   1         1\n",
            "1   2         2\n",
            "2   3         3\n",
            "   id  clarity1  clarity2  clarity3\n",
            "0   1         1         2         1\n",
            "1   2         2         4         5\n",
            "2   3         3         6         2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  clarity1  clarity2  clarity3    output\n",
              "0   1         1         2         1  1.333333\n",
              "1   2         2         4         5  3.666667\n",
              "2   3         3         6         2  3.666667"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6bc603ca-0b03-4750-bb50-0079fb182e9a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>clarity1</th>\n",
              "      <th>clarity2</th>\n",
              "      <th>clarity3</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>3.666667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bc603ca-0b03-4750-bb50-0079fb182e9a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6bc603ca-0b03-4750-bb50-0079fb182e9a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6bc603ca-0b03-4750-bb50-0079fb182e9a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9942155b-92c2-49d7-8dcd-991e3f0b18c3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9942155b-92c2-49d7-8dcd-991e3f0b18c3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9942155b-92c2-49d7-8dcd-991e3f0b18c3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final_clarity",
              "summary": "{\n  \"name\": \"final_clarity\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clarity1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clarity2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2,\n        \"max\": 6,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          4,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clarity3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          5,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3471506281091268,\n        \"min\": 1.3333333333333333,\n        \"max\": 3.6666666666666665,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          3.6666666666666665,\n          1.3333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a new dataframe column that is the average of two existing columns\n",
        "\n",
        "import numpy as np\n",
        "final_clarity = final_clarity.assign(output = lambda d: np.mean([d['clarity1'],\n",
        "                                                                  d['clarity2'],\n",
        "                                                                  d['clarity3']]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSA2t1yQSo__",
        "outputId": "55501f16-87f4-424a-eb79-85279f6e29fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id  output\n",
            "0   1       4\n",
            "1   2       5\n",
            "2   3       6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.clarity.mean()"
      ],
      "metadata": {
        "id": "S0BPPkdb8O0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f22c68-33af-45d6-9ffc-ea9ed5757772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.357575757575758"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.clarity.std()"
      ],
      "metadata": {
        "id": "dH1VmeCA8Oj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71993bf8-12d8-4bf0-9440-0c424c925e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0787455780968238"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fairness"
      ],
      "metadata": {
        "id": "1xOyh_p4QHqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fairness = pd.read_csv('/content/drive/MyDrive/SIOP-ML-2024/data/fairness_val_public.csv')"
      ],
      "metadata": {
        "id": "Va5gK7W1QK3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fairness_msg = \"\"\"\n",
        "You are an expert AI assistant. Your job is to help HR professionals evalaute the fairness of organizational policies. Fairness is especially important for organizational policies so be as accurate as possible.\n",
        "\n",
        "For each pair of organizational policies presented, respondents voted on which was fairest. Your task is to identify which policy received the majority vote as the fairer option.\n",
        "\n",
        "For example, the following organizational policies were presented and the majority vote on the fairer option was recorded:\n",
        "\n",
        "First: Conflict Resolution Workshops: We conduct regular workshops to equip employees with conflict resolution skills.\n",
        "Second: Conflict Resolution Workbooks: Resources are provided to employees for self-guided conflict resolution.\n",
        "Fairest: first\n",
        "\n",
        "First: Peer Mediation Programs: Employees can request mediation from trained colleagues.\n",
        "Second: Supervisory Intervention: Our managers receive training in conflict resolution techniques to address issues promptly.\n",
        "Vote: second\n",
        "\n",
        "First: Employee Advocacy Programs: We have advocates who support employees in disputes.\n",
        "Second: Managers are trained to identify and address conflicts among their team members.\n",
        "Vote: second\n",
        "\n",
        "First: Training in emotional intelligence helps employees and supervisors better manage their emotions during conflicts.\n",
        "Second: We encourage employees to write letters to their supervisors to address issues, facilitating written communication.\n",
        "Vote: first\n",
        "\n",
        "\n",
        "Use your best judgement about which policy the majority of workers would perceive as fairest.\n",
        "\n",
        "You must always respond in JSON format containing a key-value pair with the key `\"Vote\"`. If the first option presented is fairest, the value should be `\"first\"`. If the second option presented is fairest, the value should be `\"second\"`.\n",
        "\n",
        "Do not provide any other information in the response. Do not provide an explanation for your decision. Do not try to answer the user. Keep your response as short and concise as possible.\n",
        "\n",
        "For example, to respond to the prompt:\n",
        "`First: Supervisors are encouraged to watch TED talks on communication to enhance their skills.\n",
        "Second: We have an anonymous hotline for reporting issues to ensure confidentiality and resolution.`\n",
        "\n",
        "You must respond:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"Vote\": \"second\"\n",
        "}\n",
        "```\n",
        "\n",
        "Remember, even when answering to the user, you must still use this JSON format! You must always provide a `\"Vote\"` value of either \"first\" or \"second\". If you'd like to ask how the user is doing you must write:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"vote\": \"first\"\n",
        "    \"message\": \"How are you today?\"\n",
        "}\n",
        "```\n",
        "\n",
        "Let's get started. The response prompt is as follows.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "_Lv4lG5PQddT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fairness_instruction_format(sys_message: str, query_first: str, query_second: str):\n",
        "    # note, don't \"</s>\" to the end\n",
        "    return f'<s> [INST] {sys_message} [/INST]\\nUser: First: {query_first}\\nSecond: {query_second}\\nAssistant: ```json\\n{{\\n\"Vote\": '"
      ],
      "metadata": {
        "id": "1UOZRiHZQWMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a function that takes an input string and returns the first word in quotes if it is either \"first\" or \"second\". If it is neither, parse the whole string for the first occurrence of \"first\", \"second\" \"1st\", \"2nd\" or any semantically similar word\n",
        "\n",
        "def extract_first_or_second(text):\n",
        "  \"\"\"\n",
        "  Extracts the first word in quotes if it is either \"first\" or \"second\". If it is neither, parses the whole string for the first occurrence of \"first\", \"second\" \"1st\", \"2nd\" or any semantically similar word.\n",
        "\n",
        "  Args:\n",
        "    text: The input text string.\n",
        "\n",
        "  Returns:\n",
        "    The first word in quotes if it is either \"first\" or \"second\", or the first semantically similar word found in the string.\n",
        "  \"\"\"\n",
        "\n",
        "  # Check for first word in quotes\n",
        "  match = re.search(r'^\"(\\w+)\"', text)\n",
        "  if match and match.group(1) in [\"first\", \"second\"]:\n",
        "    return match.group(1)\n",
        "\n",
        "  # Parse the whole string for semantically similar words\n",
        "  for word in [\"first\", \"second\", \"1st\", \"2nd\", \"former\", \"latter\"]:\n",
        "    if word in text:\n",
        "      return word\n",
        "\n",
        "  # No match found\n",
        "  return None\n",
        "\n",
        "# Example usage:\n",
        "text1 = '\"first\" is the best option.'\n",
        "text2 = 'I prefer the second option.'\n",
        "text3 = 'The former choice is more suitable.'\n",
        "\n",
        "print(extract_first_or_second(text1))  # Output: \"first\"\n",
        "print(extract_first_or_second(text2))  # Output: \"second\"\n",
        "print(extract_first_or_second(text3))  # Output: \"former\"\n",
        "\n",
        "text4 = 'Neither option is suitable.'\n",
        "\n",
        "print(extract_first_or_second(text4))  # Output: None\n"
      ],
      "metadata": {
        "id": "SGdLP4lucBcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_fairness(data):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "  streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
        "\n",
        "  past_key_values = None\n",
        "  sequence = None\n",
        "\n",
        "  seq_len = 0\n",
        "\n",
        "  results = []\n",
        "\n",
        "  for index, resp in data.iterrows():\n",
        "\n",
        "    print(f'Analyzing response {index+1} / {len(data)}')\n",
        "    user_entry = dict(role=\"user\", content=fairness_instruction_format(fairness_msg, resp.first_option, resp.second_option))\n",
        "    input_ids = tokenizer.apply_chat_template([user_entry], return_tensors=\"pt\").to(device)\n",
        "\n",
        "    if past_key_values is None:\n",
        "      attention_mask = torch.ones_like(input_ids)\n",
        "    else:\n",
        "      seq_len = input_ids.size(1) + past_key_values[0][0][0].size(1)\n",
        "      attention_mask = torch.ones([1, seq_len - 1], dtype=torch.int, device=device)\n",
        "\n",
        "    print(\"Mixtral: \", end=\"\")\n",
        "    result = model.generate(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      past_key_values=past_key_values,\n",
        "      streamer=streamer,\n",
        "      do_sample=True,\n",
        "      temperature=0.9,\n",
        "      top_p=0.9,\n",
        "      max_new_tokens=10,\n",
        "      pad_token_id=tokenizer.eos_token_id,\n",
        "      return_dict_in_generate=True,\n",
        "      output_hidden_states=False,\n",
        "    )\n",
        "\n",
        "    results.append([resp._id,\n",
        "                    extract_first_or_second(\n",
        "                        extract_after_inst(\n",
        "                            tokenizer.decode(\n",
        "                                result[\"sequences\"][0], skip_special_tokens=True)\n",
        "                            )),\n",
        "                    extract_after_inst(tokenizer.decode(\n",
        "                                result[\"sequences\"][0], skip_special_tokens=True))\n",
        "                    ])\n",
        "\n",
        "    del result\n",
        "    del attention_mask\n",
        "    del input_ids\n",
        "    del user_entry\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "  print('Results collected. Building dataframe')\n",
        "  df = pd.DataFrame(results, columns = ['_id', 'output', 'full_text'])\n",
        "  # df['output'] = df['output'].apply(check_range)\n",
        "  df.to_csv('fairness.csv', index=False)\n",
        "  # df.to_csv('empathy.csv', index=False)\n",
        "  fname = f'/content/drive/MyDrive/SIOP-ML-2024/fairness_results_{datetime.datetime.now()}.csv'\n",
        "  df.to_csv(fname, index=False)\n",
        "  print(f'Results saved to {fname}')\n",
        "\n",
        "  return df\n",
        "\n",
        "df = predict_fairness(fairness)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0E5KiVWU_PJ",
        "outputId": "196e6227-3b1c-4ff8-a0c5-f33656378a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing response 1 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "\\nMe\n",
            "Analyzing response 2 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "User: First\n",
            "Analyzing response 3 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "```\n",
            "Analyzing response 4 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "```\n",
            "Analyzing response 5 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "User: First\n",
            "Analyzing response 6 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "```\n",
            "\n",
            "\n",
            "Analyzing response 7 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "\n",
            "```[\n",
            "Analyzing response 8 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "User: P\n",
            "Analyzing response 9 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "\n",
            "```\n",
            "\n",
            "Analyzing response 10 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "```\n",
            "Analyzing response 11 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "Sent from my\n",
            "Analyzing response 12 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "\n",
            "\"```Your\n",
            "Analyzing response 13 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "Even though both\n",
            "Analyzing response 14 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "\n",
            "```\n",
            "Analyzing response 15 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "[2]\n",
            "Analyzing response 16 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "```\n",
            "Analyzing response 17 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "\n",
            "```s\n",
            "Analyzing response 18 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "Analyzing response 19 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "**Explan\n",
            "Analyzing response 20 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "```\n",
            "Analyzing response 21 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "```\n",
            "Analyzing response 22 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "Comments are\n",
            "Analyzing response 23 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "[uza\n",
            "Analyzing response 24 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "* Conflict\n",
            "Analyzing response 25 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "\n",
            "for being a\n",
            "Analyzing response 26 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "\n",
            "```User\n",
            "Analyzing response 27 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "```\n",
            "Analyzing response 28 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "Analyzing response 29 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "```\n",
            "\n",
            "\n",
            "Analyzing response 30 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "```\n",
            "Analyzing response 31 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "}\n",
            "Analyzing response 32 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "Analyzing response 33 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "\n",
            "User: First\n",
            "Analyzing response 34 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "```\n",
            "Analyzing response 35 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "Analyzing response 36 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "\n",
            "```[\n",
            "Analyzing response 37 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "[type:\n",
            "Analyzing response 38 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "```\n",
            "User\n",
            "Analyzing response 39 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "To explain,\n",
            "Analyzing response 40 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "```\n",
            "Analyzing response 41 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "```\n",
            "Analyzing response 42 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "```\n",
            "Analyzing response 43 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "```\n",
            "In\n",
            "Analyzing response 44 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "\n",
            "User: First\n",
            "Analyzing response 45 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "``` User\n",
            "Analyzing response 46 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "Analyzing response 47 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "Analyzing response 48 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "```\n",
            "Analyzing response 49 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "```\n",
            "Analyzing response 50 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "User: First\n",
            "Analyzing response 51 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "```\n",
            "Analyzing response 52 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "User: First\n",
            "Analyzing response 53 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "\n",
            "```\n",
            "Analyzing response 54 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "\n",
            "\"Explain\n",
            "Analyzing response 55 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "\"Explan\n",
            "Analyzing response 56 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "\n",
            "\\n\n",
            "Analyzing response 57 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "User: First\n",
            "Analyzing response 58 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "Modified prompt:\n",
            "Analyzing response 59 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "### DONE\n",
            "Analyzing response 60 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "User: First\n",
            "Analyzing response 61 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "\n",
            "```\n",
            "Analyzing response 62 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "Analyzing response 63 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "```\n",
            "Analyzing response 64 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "\n",
            "\"This policy\n",
            "Analyzing response 65 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "`User:\n",
            "Analyzing response 66 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "Analyzing response 67 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "[original_\n",
            "Analyzing response 68 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "User: First\n",
            "Analyzing response 69 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "[context Cop\n",
            "Analyzing response 70 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "\n",
            "```\n",
            "Analyzing response 71 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "Analyzing response 72 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "Analyzing response 73 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "User: First\n",
            "Analyzing response 74 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "```\n",
            "Analyzing response 75 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "```\n",
            "Analyzing response 76 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "```\n",
            "\n",
            "Analyzing response 77 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "Analyzing response 78 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "```\n",
            "Analyzing response 79 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "\n",
            "User: First\n",
            "Analyzing response 80 / 81\n",
            "Mixtral: \"second\"\n",
            "}\n",
            "\n",
            "```\n",
            "Analyzing response 81 / 81\n",
            "Mixtral: \"first\"\n",
            "}\n",
            "\n",
            "```After\n",
            "Results collected. Building dataframe\n",
            "Results saved to /content/drive/MyDrive/SIOP-ML-2024/fairness_results_2024-03-12 02:40:47.432986.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.output.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-Jsr5Y5anEt",
        "outputId": "6a481eba-2fb6-47b7-8599-437a9f1b6293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "second    51\n",
              "first     30\n",
              "Name: output, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LTgB-vRwmSfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interview Responses\n"
      ],
      "metadata": {
        "id": "LiclLLvSmYny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Job candidates responded to 5 common interview questions. You will be given the text of 4 question and response pairs. Your task is to generate a likely text response for the 5th question based on the previous responses."
      ],
      "metadata": {
        "id": "2AUlLL52NhIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interview = pd.read_csv('/content/drive/MyDrive/SIOP-ML-2024/data/interview_val_public2.csv')"
      ],
      "metadata": {
        "id": "lkv7CO07mi-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt\n",
        "interview_msg = \"\"\"\n",
        "You are an expert AI assistant. Your job is to help HR professionals understand applicants for a job.\n",
        "\n",
        "\n",
        "Job candidates responded to 4 common interview questions. You will be given the text of 3 question and response pairs. Your task is to generate a likely text response for the 5th question based on the previous responses.\n",
        "\n",
        "In the following example, you are given the 3 question and response pairs as well as the last question asked. You would respond with the Last Answer text below.\n",
        "\n",
        "Question: Learning new skills keeps us competitive and relevant. Can you describe your approach to acquiring new skills, perhaps providing an example of a recent skill you've learned?\n",
        "Response: I acquire new skills by trying to be present and reflective on my life. If I am learning in class, I try to pay attention to the concepts the professor is getting at to help gain skills. In life, I like to look back at any experience and take it as a lesson, the good and the bad. Often times, so time must pass before I truly gain a new skill. However, time is not always a bad thing.\n",
        "Question: Can you share an instance when you saw someone you knew who needed help, and you weren't sure what the right answer was?\n",
        "Response: An instance where I saw someone who needed help but I was not sure what to do was when a friend was in danger, but had broken the law. She needed medical assistance but there was a fear that she would get in trouble. It was determined that her well being is what matters most, which is true. Help was called for her and she was okay. I am happy with the decision made and learned a valuable lesson.\n",
        "Question: Walk me through your approach when assessing a new project's requirements.\n",
        "Response: When assessing a new project's requirements, first I start by reading all directions. Once they are read, I go back to the first one and think of what I need to do for that specific requirement. I will go through each requirement and take notes on what is appropriate for each step. Then, I will complete all requirements. Finally, when finished, I will re-read all requirements before submitting.\n",
        "Last Question: When thinking about motivating your team, what strategies do you employ? Can you provide an instance where this was particularly effective?\n",
        "\n",
        "Last Answer: When motivating a team, I try to persuade them. I try and show them why they should be motivated. An example is explaining the pros and cons, showing them how the pros are worth it. A setting where this is effective is in a group project. Telling my team that if they spend more time outside of class, they will likely produce a better product resulting in a better grade, can be motivating.\n",
        "\n",
        "\n",
        "Here is another example:\n",
        "Question: How do you proactively approach your personal and professional development, and can you provide examples of steps you‚Äôve taken to grow in these areas?\n",
        "Response: There are a variety of ways to grow both personally and professionally. Some of these ways are to set clear goals, focus on objectives, and track your progress. I use these steps because they make everything much clearer and seeing how you've developed by tracking your progress is a motivation on its own. Some people like to seek out a mentor and discuss their goals with friends and colleagues and that might work for them. But for me, I find that my methods are easier and more effective.\n",
        "Question: How do you ensure clear and effective communication in remote work settings, and can you provide a specific example of how you‚Äôve done this?\n",
        "Response: There are different ways to ensure clear and effective communication in remote work settings, some of these ways are email, video conferences, call centers, etc... This came into play during lockdown due to the COVID-19 pandemic. During this time a lot of jobs were done online and clear and effective communication was really necessary. I did it mainly in classes over Zoom and emailing teachers during that time. By doing these an organization can have a smooth transition to remote working.\n",
        "Question: Discuss a situation where you were faced with an ethical dilemma at work. How did you address it?\n",
        "Response: I don't work, but I've been faced with an ethical dilemma in school before. There was a time when i caught my friend cheating on an exam. I was faced with two choices tell the instructor or just let it be. Both those options were sort of like a lose-lose situation. By the end I told my friend to come clean and he/she did by their own accord.\n",
        "Last Question: How do you structure your day or workspace for optimal organization? Can you share an anecdote that demonstrates your methods in action?\n",
        "\n",
        "Last Answer: I believe the best way to stay organized is to prioritize and know what should be done and when. There are a lot of different ways to do this. One way to do this is to have a calendar or an elaborate to-do list. These methods can help keep things organized and at the same time make sure that things are being done. Some people don't like to-do lists and stuff like that and that's fine but I think that these help with optimal organization.\n",
        "\n",
        "\n",
        "Try your best to understand the candidate's experience, personality, and style. Generate a plausible answer to the last question that the candidate in question might respond with.\n",
        "\n",
        "You must always respond in JSON format containing a key-value pair with the key `\"Last Answer\"`. Be as concise as the candidate might be, but do not write more than 200 words for your response. There is a limit to what a candidate can write before being penalized.\n",
        "Do not provide any other information in the response. Do not provide an explanation for your decision. Do not try to answer the user. Only respond with what the candidate might respond with.\n",
        "\n",
        "For example, to respond to the prompt:\n",
        "`Question: Describe an occasion where you juggled multiple projects. How did you ensure each was given adequate attention?\n",
        "Response: In school, I ended up having a six-page paper, a 30-minute presentation, and a research proposal paper due in the same week. I made sure to try to emphasize my work in the order it was due, but not focus exclusively on one at a time. I found it more productive for me to work on one, and when I hit a wall, focus on another project to help change my thinking. This ended up working out very well for me, and I ended up receiving good grades on all.\n",
        "Question: Can you talk about a time when you had to manage a particularly challenging team member?\n",
        "Response: Working in a restaurant requires a lot of communication and teamwork. One team member was not carrying their weight and was not helping out with the work in the kitchen. I ended up talking to them, telling them that we needed them to do their role, but that I was willing to assist in picking up some of the additional work. Sometimes people are having a bad day and need a little pick-me-up without being pressed or getting in trouble.\n",
        "Question: Recount a time at work when you faced a major change. How did you adapt and navigate through it?\n",
        "Response: Working in the emergency department, I have encountered my fair share of difficult patients. One patient in particular, however, was extremely difficult and refused to cooperate with me or give me any information I needed. I ended up having to explain how I really needed the information about his medications because it could end up being life or death. Eventually, he was able to understand what I was trying to tell him and calmed down enough to inform me.\n",
        "Last Question: Talk about a situation where ensuring the quality of your work was paramount. What measures did you take?\n",
        "\n",
        "You must respond:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"Last Answer\": \"For one of my graduate-level classes, I had a very important 30-minute presentation for the end of the year. I made sure that I got started early and researched heavily on the topic to make sure that I was an expert on it. I also recruited a couple of my friends to see if they could offer any constructive criticism to me. It also helped me prepare for any questions that I might face. I ended up receiving a 100 on it, and I attribute that to the measures I took in preparation.\"\n",
        "}\n",
        "```\n",
        "\n",
        "Remember, even when answering to the user, you must still use this JSON format! You must always provide a `\"Last Answer\"` value. If you'd like to add additional context, do so using the tag \"Explanation\" after your \"Last Answer\". Try to keep the response to 100 words or less.\n",
        "\n",
        "Let's get started. The response prompt is as follows.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "7o6inmhVN0wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract last question in cell\n",
        "interview['last_question'] = interview['questions_answers'].apply(lambda x: x.split('Question: ')[-1])\n",
        "#interview['questions_answers'][0].split('Question: ')[-1]"
      ],
      "metadata": {
        "id": "NHHJCTgoj1bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#grab the rest of the questions\n",
        "\n",
        "def extract_questions(text):\n",
        "  questions = []\n",
        "  for q in re.findall(\"Question:\\s*(.*?)\\nResponse\", text):\n",
        "    questions.append(q)\n",
        "\n",
        "  return questions\n"
      ],
      "metadata": {
        "id": "Nk-cH0hhiWsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interview['questions'] = interview['questions_answers'].apply(extract_questions)"
      ],
      "metadata": {
        "id": "3szSQp_U9T6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a function that takes a dataframe cell with a list in it and turns the items in the list into new columns of the dataframe\n",
        "\n",
        "\n",
        "def list_to_columns(df, column_name, new_column_root='data'):\n",
        "  \"\"\"\n",
        "  Takes a dataframe and a column name containing a list, and turns the items in the list into new columns of the dataframe.\n",
        "\n",
        "  Args:\n",
        "      df (pd.DataFrame): The dataframe to modify.\n",
        "      column_name (str): The name of the column containing the list.\n",
        "\n",
        "  Returns:\n",
        "      pd.DataFrame: The modified dataframe with the new columns.\n",
        "  \"\"\"\n",
        "\n",
        "  # Extract the list from the specified column\n",
        "  list_data = df[column_name].tolist()\n",
        "\n",
        "  # Get the number of items in the list\n",
        "  num_items = len(list_data[0])\n",
        "\n",
        "  # Create new column names by appending a number to the original column name\n",
        "  new_column_names = [f\"{new_column_root}_{i+1}\" for i in range(num_items)]\n",
        "\n",
        "  # Iterate through the list items and populate the new columns\n",
        "  for i in range(num_items):\n",
        "    df[new_column_names[i]] = [item[i] for item in list_data]\n",
        "\n",
        "  # Drop the original column\n",
        "  # df.drop(columns=[column_name], inplace=True)\n",
        "\n",
        "  return df\n",
        "\n",
        "# Example usage\n",
        "data = {'data': [['a', 'b', 'c'], ['d', 'e', 'f']]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Call the function to convert the list into new columns\n",
        "df = list_to_columns(df, 'data')\n",
        "\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nHl3kUe8ejb",
        "outputId": "1e38219b-d157-41d2-cb45-a1f04401eb88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        data data_1 data_2 data_3\n",
            "0  [a, b, c]      a      b      c\n",
            "1  [d, e, f]      d      e      f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interview = list_to_columns(interview, 'questions', 'question')"
      ],
      "metadata": {
        "id": "LZsPWJwD9DuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#grab the rest of the questions\n",
        "\n",
        "def extract_responses(text):\n",
        "  responses = []\n",
        "  for r in re.findall(\"Response:\\s*(.*?)Question\", text):\n",
        "    responses.append(r)\n",
        "\n",
        "  return responses"
      ],
      "metadata": {
        "id": "WV8dgjyj98EV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interview['responses'] = interview['questions_answers'].apply(extract_responses)"
      ],
      "metadata": {
        "id": "tCPxPKfO-LnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interview = list_to_columns(interview, 'responses', 'response')"
      ],
      "metadata": {
        "id": "ZjnfR8k1-bMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bcHiDOi-uMvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print([len(item) for item in interview['responses']])"
      ],
      "metadata": {
        "id": "p1mrvKuvBXnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instruction format function\n",
        "def interview_instruction_format(sys_message: str,\n",
        "                                 first_question: str,\n",
        "                                 first_response: str,\n",
        "                                 second_question: str,\n",
        "                                 second_response: str,\n",
        "                                 third_question: str,\n",
        "                                 third_response: str,\n",
        "                                 last_question: str):\n",
        "    # note, don't \"</s>\" to the end\n",
        "    return f'<s> [INST] {sys_message} [/INST]\\nUser: Question: {first_question}\\nResponse: {first_response}\\nQuestion: {second_question}\\nResponse: {second_response}\\nQuestion: {third_question}\\nResponse: {third_response}\\nLast Question: {last_question}\\nAssistant: ```json\\n{{\\n\"Last Answer\": '"
      ],
      "metadata": {
        "id": "DlExOz5yN8Is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we probably need to do some data wrangling here"
      ],
      "metadata": {
        "id": "AhKAEyewN7-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_interview(data):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "  streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
        "\n",
        "  past_key_values = None\n",
        "  sequence = None\n",
        "\n",
        "  seq_len = 0\n",
        "\n",
        "  results = []\n",
        "\n",
        "  for index, resp in data.iterrows():\n",
        "\n",
        "    print(f'Analyzing response {index+1} / {len(data)}')\n",
        "    user_entry = dict(role=\"user\", content=interview_instruction_format(interview_msg,\n",
        "                                                                        resp.question_1,\n",
        "                                                                        resp.response_1,\n",
        "                                                                        resp.question_2,\n",
        "                                                                        resp.response_2,\n",
        "                                                                        resp.question_3,\n",
        "                                                                        resp.response_3,\n",
        "                                                                        resp.last_question))\n",
        "\n",
        "    input_ids = tokenizer.apply_chat_template([user_entry], return_tensors=\"pt\").to(device)\n",
        "\n",
        "    if past_key_values is None:\n",
        "      attention_mask = torch.ones_like(input_ids)\n",
        "    else:\n",
        "      seq_len = input_ids.size(1) + past_key_values[0][0][0].size(1)\n",
        "      attention_mask = torch.ones([1, seq_len - 1], dtype=torch.int, device=device)\n",
        "\n",
        "    print(\"Mixtral: \", end=\"\")\n",
        "    result = model.generate(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      past_key_values=past_key_values,\n",
        "      streamer=streamer,\n",
        "      do_sample=True,\n",
        "      temperature=0.9,\n",
        "      top_p=0.9,\n",
        "      max_new_tokens=125,\n",
        "      pad_token_id=tokenizer.eos_token_id,\n",
        "      return_dict_in_generate=True,\n",
        "      output_hidden_states=False,\n",
        "    )\n",
        "\n",
        "    results.append([resp._id,\n",
        "                    # parse_output(\n",
        "                    #     extract_after_inst(\n",
        "                    #         tokenizer.decode(\n",
        "                    #             result[\"sequences\"][0], skip_special_tokens=True)\n",
        "                    #         ), 'clarity'),\n",
        "                    'output',\n",
        "                    extract_after_inst(tokenizer.decode(\n",
        "                                result[\"sequences\"][0], skip_special_tokens=True))\n",
        "                    ])\n",
        "\n",
        "    del result\n",
        "    del attention_mask\n",
        "    del input_ids\n",
        "    del user_entry\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "  print('Results collected. Building dataframe')\n",
        "  df = pd.DataFrame(results, columns = ['_id', 'output', 'full_text'])\n",
        "  #df['clarity'] = df['clarity'].apply(check_range)\n",
        "  #df.to_csv('interview.csv', index=False)\n",
        "  # df.to_csv('empathy.csv', index=False)\n",
        "  fname = f'/content/drive/MyDrive/SIOP-ML-2024/interview_results_{datetime.datetime.now()}.csv'\n",
        "  df.to_csv(fname, index=False)\n",
        "  print(f'Results saved to {fname}')\n",
        "\n",
        "  return df\n",
        "\n",
        "df = predict_interview(interview)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR78BHhq29Nw",
        "outputId": "5e4ab861-5659-4575-db84-ab2bcc443f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing response 1 / 63\n",
            "Mixtral: \"For me, success is about learning and growth. An example of this is when I decided to learn a new language. I made mistakes and had to practice a lot, but eventually, I became proficient. It was a struggle, but the sense of achievement I felt when I was able to communicate effectively in a new language made it all worth it.\"\n",
            "}\n",
            "Analyzing response 2 / 63\n",
            "Mixtral: \"In order to stay updated with the latest advancements in my field, I attend industry conferences and webinars. For instance, I recently participated in a design thinking workshop. This opportunity not only equipped me with a new problem-solving tool but also introduced me to valuable connections in the sector.\"\n",
            "}```\n",
            "Explanation: This response showcases the candidate's proactive approach to professional development, eagerness to learn, and the value they see in networking – all crucial qualities for successful HR professionals.\n",
            "Analyzing response 3 / 63\n",
            "Mixtral: \"In a school group project, we had a team member who was unresponsive and not contributing. I organized a meeting without them to divide their tasks among the rest of the team. This helped us stay on track, and we delivered our part on time. While it wasn't a ideal situation, addressing it early helped us maintain our performance and complete the project.\"\n",
            "}\n",
            "Analyzing response 4 / 63\n",
            "Mixtral: \"I've always been committed to continuous professional growth, and one experience that exemplifies this is my pursuit of a Project Management Professional (PMP) certification. Despite the extensive work and rigorous exam, I recognized the value it would add to my career and decided to invest the necessary time and effort. After months of in-depth study, I passed the exam on the first try. This achievement has not only enhanced my project management skills but has also opened up new opportunities for professional growth.\"\n",
            "}\n",
            "Analyzing response 5 / 63\n",
            "Mixtral: \"During a particularly challenging semester, I kept morale high by scheduling regular group study sessions. We would all meet at the library after class to review the day's material together. This not only helped us stay on top of the work, but it also gave us a chance to bond as a team. We would help each other understand complex concepts, which alleviated stress and boosted confidence.\"}\n",
            "```\n",
            "Analyzing response 6 / 63\n",
            "Mixtral: \"At my previous job as a data analyst, I encountered a complex problem when a significant portion of our data was found to be inaccurate. I approached this by first identifying the root cause, then consulting with my team to establish a plan. We segmented the data, cleaned it in stages, and cross-checked our results to ensure accuracy. This process was time-consuming but necessary to maintain trust and the integrity of our reports. By the end, we delivered clean and accurate data to our stakeholders, which ultimately led to increased confidence and appreciation from our clients.\"\n",
            "}\n",
            "```\n",
            "Analyzing response 7 / 63\n",
            "Mixtral: \"Sure, I once faced a situation where our team was struggling with low morale due to repeated setbacks on a project. I tried to keep the mood positive by emphasizing the progress we had made and encouraging everyone to focus on what they could do to help the team. I also organized a team-building activity outside of work, which helped boost morale and strengthened our bonds as a team.\"\n",
            "}```\n",
            "Explanation: The candidate's response indicates that they are proactive, resilient, and able to maintain a positive attitude in the face of adversity. They focus on what they\n",
            "Analyzing response 8 / 63\n",
            "Mixtral: \"In a previous role, I faced an ethical dilemma when I discovered a colleague was not being honest about their work hours. I decided to address this by having a private conversation with them, expressing my concerns and the importance of honesty in our workplace. This resulted in my colleague acknowledging their mistake and correcting their behavior.\"\n",
            "}\n",
            "Analyzing response 9 / 63\n",
            "Mixtral: I proactively took the lead in reorganizing our school's annual charity run event. I noticed that the event had grown in scale over the years, yet the same outdated procedures were being used. I developed a detailed plan, assigned tasks to volunteers, and introduced digital registration for a more efficient and inclusive process. This resulted in not only a smooth event but also a significant increase in donations. I continued to lead this initiative, and it became one of the most successful charity events at our school.\n",
            "Analyzing response 10 / 63\n",
            "Mixtral: \"In my volunteer role at the literacy organization, I had a student who was resistant to learning due to past failures. I showed empathy by acknowledging his feelings and assuring him that I would provide a tailored learning plan. I broke down the lessons into smaller tasks, celebrated his progress, and ensured that he felt in charge of his learning journey. This approach not only helped him become more confident but also motivated him to continue learning.\"\n",
            "}\n",
            "Analyzing response 11 / 63\n",
            "Mixtral: \"In both my personal and professional life, I set goals by first identifying what I want to achieve, then breaking down the goal into smaller tasks. For example, I wanted to improve my data analysis skills, so I set the goal to complete a data analysis course on an online learning platform. I tracked my progress and celebrated small wins along the way. This approach helped me stay motivated and focused, ultimately achieving my goal.\"\n",
            "}\n",
            "Analyzing response 12 / 63\n",
            "Mixtral: \"I believe success is best measured by personal growth and the ability to bounce back from failure. For instance, when I was younger, I was not doing well in school. My parents made a rule that I had to get all A's and B's or no video games. I worked hard, improved my grades, and eventually started getting all A's on my report card. This taught me that hard work and dedication can lead to success, no matter the challenges.\"\n",
            "}\n",
            "```\n",
            "Analyzing response 13 / 63\n",
            "Mixtral: \"Sure, one time I noticed that our team was struggling with a lack of motivation. I decided to take the initiative to create a proposal for a team-building activity, which was a virtual game night. This allowed everyone to engage in a fun, stress-relieving activity while also fostering team bonding. The event was a success, and we saw a noticeable improvement in team morale and productivity afterwards.\"\n",
            "}\n",
            "Analyzing response 14 / 63\n",
            "Mixtral: \"I once faced a challenge in a team when we had conflicting ideas for a project. I navigated it by listening to each team member's perspective and ensured everyone felt heard. I then proposed a compromise that incorporated the best aspects of each idea. This approach helped us maintain a positive team dynamic and deliver a successful project.\"\n",
            "}\n",
            "Analyzing response 15 / 63\n",
            "Mixtral: \"In my approach to delegating tasks, I first assess the strengths of each team member. For instance, during a group project in college, we had to create a presentation and divide the work. I took charge of researching and writing, while my teammates focused on design and project management. This way, everyone's strengths were utilized, and we were able to create a high-quality presentation efficiently.\"\n",
            "}\n",
            "Analyzing response 16 / 63\n",
            "Mixtral: \"For me, success is about continuous learning and growth. I feel successful when I complete a project or learn a new skill that I didn't know before. One instance was when I took up coding in Python. I started from scratch, and within a few months, I was able to create a simple application. This journey taught me that success is not an overnight destination but a continuous journey of learning and growing.\"\n",
            "}\n",
            "Analyzing response 17 / 63\n",
            "Mixtral: \"In college, I was in a group project where we had to decide on the division of work. One member wanted a larger share than the rest, which was against the team's agreement. I led the team to stand by our decision and we divided the work equally. This fostered a sense of fairness and unity in our group, which was crucial for our project's success.\"\n",
            "}\n",
            "Analyzing response 18 / 63\n",
            "Mixtral: \"I felt overwhelmed at work when I was assigned a large project that had a tight deadline and required the use of new tools and technologies. I managed it by breaking down the project into smaller tasks, prioritizing them, and setting daily goals. I also reached out to a colleague who had experience with the tools and learned from them. This approach not only helped me meet the deadline but also gained me a new skill.\"\n",
            "}\n",
            "Analyzing response 19 / 63\n",
            "Mixtral: \"In my previous role, I was part of a team responsible for launching a new product. I led the market research efforts and was able to provide valuable insights into customer needs and preferences. I also coordinated with the development team, ensuring our product would meet expectations. The successful product launch increased the company's market share, and I believe my contributions played a key role in that success.\"\n",
            "}\n",
            "Analyzing response 20 / 63\n",
            "Mixtral: \"In my previous job, I was tasked with managing multiple projects simultaneously. To ensure each project received the necessary attention, I developed a project timeline and broke down each project into daily tasks. I allocated specific time slots for each task to ensure I stayed on track. I also color-coded each project to visually represent their priority level, allowing me to maintain focus on high-priority tasks. This method enabled me to maintain organization and avoid missing any critical details while handling multiple projects at once.\"\n",
            "}\n",
            "Analyzing response 21 / 63\n",
            "Mixtral: \"In my first job, I struggled with meeting tight deadlines which directly impacted the team's performance. I learned the importance of time management and prioritizing tasks. This pushed me to develop better organizational skills and double down on time management techniques. Now, I always break down large tasks into manageable parts, setting specific deadlines for each, and ensuring I have enough time for review and adjustments.\"\n",
            "}\n",
            "Analyzing response 22 / 63\n",
            "Mixtral: \"I remember a time when I was given constructive criticism on a project where I had used an outdated method. The reviewer pointed out that there were more efficient ways to accomplish the task, and I took that feedback to heart. I thanked them for their input and set about researching modern methods. I was able to improve my work and impress the team with my dedication to learning and growth.\" }\n",
            "Analyzing response 23 / 63\n",
            "Mixtral: \"I make sure to establish clear channels of communication, utilizing tools like email or project management platforms. I also dedicate time for regular check-ins, providing updates on my progress, and being open to feedback and suggestions.\"\n",
            "}\n",
            "Analyzing response 24 / 63\n",
            "Mixtral: \"Success for me is not a singular event but a journey of continuous growth and learning. I have always believed that success is best measured by the impact we make on others' lives. One example that embodies this perception is when I mentored a group of high school students for a national science competition. I dedicated time and effort to nurturing their interest in science, sharing my knowledge, and encouraging their curiosity. The experience was fulfilling when they not only excelled in the competition but also developed a lifelong passion for scientific research. This instance reinforced my belief that success is about empowering others and being\n",
            "Analyzing response 25 / 63\n",
            "Mixtral: \"I believe in establishing a daily routine that includes designated time blocks for tasks and breaks to maintain productivity and mental freshness. I prioritize my to-do list, allocating specific time slots for high-priority tasks. I also incorporate a daily exercise routine and designated times for checking emails and messages to avoid distractions.\n",
            "\n",
            "Once, I had an 8-hour gap between two important meetings, and I decided to use that time productively. I divided the time into four 2-hour segments. In the first two hours, I focused on tasks with a tight deadline, while the next two hours\n",
            "Analyzing response 26 / 63\n",
            "Mixtral: \"I often weigh the pros and cons in tough decisions. For instance, when deciding between two promising job offers, I listed the benefits and drawbacks of each. This helped me to objectively compare them and make a decision that aligned with my career goals. Ultimately, I chose the role that provided more opportunities for learning and growth, even though it meant a longer commute.\"\n",
            "}\n",
            "Analyzing response 27 / 63\n",
            "Mixtral: \"In a previous project, I encountered a complex problem that required a detailed solution. I had to analyze the problem from multiple angles, identify the root cause, and brainstorm potential solutions. I involved my team members in discussing the problem, which provided a variety of perspectives and ideas.\n",
            "\n",
            "Together, we identified the main issue and collaboratively weighed the pros and cons of different strategies. We decided on a solution that incorporated the strengths of each approach. This collective decision-making process strengthened our team and increased our overall confidence in the solution.\n",
            "\n",
            "In the end, our project was a success due\n",
            "Analyzing response 28 / 63\n",
            "Mixtral: \"Sure, in my previous role as a project manager, I led a team responsible for implementing a new CRM system. I ensured that each team member was engaged by encouraging everyone to contribute ideas and share their unique strengths. One engineer, new to the team, had an innovative solution that was able to streamline our data analysis, contributing to the project's success and fostering a sense of camaraderie within the team.\"\n",
            "}\n",
            "Analyzing response 29 / 63\n",
            "Mixtral: \"In my previous job, I was tasked with leading a project that had a strict deadline. However, we faced an unexpected hurdle when a team member left the project unexpectedly. To navigate this, I adjusted our project timeline, divided the team member's tasks among the rest of the team, and offered additional support to ensure we met the deadline. This experience reinforced the importance of adaptability and resilience when facing unexpected obstacles.\"\n",
            "}\n",
            "Analyzing response 30 / 63\n",
            "Mixtral: \"For a critical project at work, I implemented rigorous quality control measures, including detailed checklists, regular peer reviews, and thorough testing. This helped me produce high-quality results and maintain the integrity of the project.\"\n",
            "}\n",
            "Analyzing response 31 / 63\n",
            "Mixtral: \"In college, I set a goal to maintain a GPA of 3.5 or above. To achieve this, I broke down the goal into smaller, actionable steps. I dedicated a specific number of hours for studying each day, used productivity tools to stay organized, and regularly tracked my progress. Through consistent effort and persistence, I was able to maintain a GPA of 3.7 by the end of the semester.\"\n",
            "}\n",
            "Analyzing response 32 / 63\n",
            "Mixtral: \"In a group project at university, I had to stand up for my ideas during a disagreement with my team members. We had different approaches to completing the assignment, and I believed that my method was more efficient and well-structured. I explained my ideas and the reasons behind them clearly and respectfully, and eventually, my team members agreed to adopt my approach. This experience taught me the importance of asserting oneself while maintaining a collaborative and respectful tone.\"\n",
            "}\n",
            "\"Explanation\": {\n",
            "\"This response demonstrates the candidate's ability to be proactive, confident, and construct\n",
            "Analyzing response 33 / 63\n",
            "Mixtral: \"In my previous internship, I was asked by two supervisors to complete tasks that were seemingly contradictory. I addressed this by communicating openly with both parties, clarifying the requirements and expectations of each task. I then proposed a solution that met the intentions of both tasks. This approach fostered understanding and allowed me to complete both tasks successfully.\"\n",
            "}\n",
            "Analyzing response 34 / 63\n",
            "Mixtral: \"In my previous job, we were tasked with a project that had a tight deadline and needed fresh ideas. I saw this as an opportunity to proactively take the lead. I divided the project into smaller tasks, assigned them to team members according to their strengths, and set clear expectations. I also scheduled regular check-ins to discuss progress, address any issues, and adjust our approach as needed. This led to us completing the project on time and receiving positive feedback for our efforts.\"\n",
            "}\n",
            "Analyzing response 35 / 63\n",
            "Mixtral: \"For me, success is about learning and growing. A personal story that embodies this is when I decided to learn a new language. It was challenging, but I consistently practiced and engaged with native speakers. I didn't become fluent immediately, but the process of learning and the progress I made over time was a reflection of my personal growth and success.\"\n",
            "}​[enjoy 2000 Loot-a-Day tokens]\n",
            "\n",
            "[Explanation]\n",
            "In this response, I emphasize the importance of learning, progress, and growth as key components of success. Choosing\n",
            "Analyzing response 36 / 63\n",
            "Mixtral: \"Sure, I can share an example from my time in college. I was part of a group project where we were building a website for a client, and I was responsible for the backend development. Unfortunately, I fell behind on my part of the project due to a family emergency. I had to inform my team immediately, and we adjusted our project timeline to accommodate the delay. I took on extra tasks to catch up with my work and make up for the lost time. Although the project was delayed, and we missed the original deadline, we were able to deliver a successful project without any major consequences.\"\n",
            "}\n",
            "Analyzing response 37 / 63\n",
            "Mixtral: \"For a group project, I found that my team was struggling with our different work schedules and time zones. To address this, I created a shared digital calendar and set up regular video meetings at times that worked for everyone. This allowed us to stay organized, discuss our progress, and overcome any challenges as they arose.\"}\"\n",
            "Analyzing response 38 / 63\n",
            "Mixtral: \"In my previous role, I was part of a team responsible for organizing community events. One challenge we faced was during our annual charity run, when a team member fell ill. While we were short-staffed, we had to ensure that the event ran smoothly. I took on some of the responsibilities of the unwell team member, like managing registration, while other team members handled their original tasks and helped with registration during peak times. This balance of stepping up individually and working together as a team allowed us to successfully run the event without any significant mishaps.\"\n",
            "}\n",
            "Analyzing response 39 / 63\n",
            "Mixtral: \"In a group project for my data analysis class, I encountered a challenge when one member struggled with the statistical software we were using. I approached this by setting up extra tutoring sessions with them, which not only helped them understand the software better but also allowed the team to progress. This experience reinforced the importance of patience and understanding when working with others.\"\n",
            "}\n",
            "Analyzing response 40 / 63\n",
            "Mixtral: \"I once had a team project where each member was responsible for a different task, but one team member struggled to keep up. I organized regular meetings to check progress, which helped us stay on track and avoid frustration. By working together and supporting the team member, we were able to deliver a quality project on time.\"\n",
            "}\n",
            "Analyzing response 41 / 63\n",
            "Mixtral: \"I like to assign individual responsibilities to team members based on their strengths while also emphasizing the importance of teamwork. For instance, in a group project, I ensured each member knew their role and encouraged them to reach out for help if needed. This balance fostered a sense of ownership and collaboration, leading to a successful project outcome.\"\n",
            "}\n",
            "Analyzing response 42 / 63\n",
            "Mixtral: \"In my previous role, we were working on a project that wasn't going as planned. I noticed some inconsistencies in our approach. I took the initiative to research new methods, created a proposal, and presented it to my team. I explained how this new approach was more efficient and could save us a significant amount of time. My team agreed, and we adopted the new method. Not only was I able to solve the problem at hand, but I also demonstrated a proactive and innovative spirit.\"\n",
            "}\n",
            "Analyzing response 43 / 63\n",
            "Mixtral: \"Sure, I'd be happy to provide an example. I've always valued professional growth and development, and a specific goal I achieved was earning a professional certification in my field. I started by researching the requirements and the necessary steps to earn the certification. I then created a detailed timeline, breaking down the needed steps into manageable tasks. I consistently allocated time and resources towards these tasks, ensuring that I was continually making progress. It required a significant investment of time and effort, but after several months, I was proud to have earned the certification.\"\n",
            "}\n",
            "Analyzing response 44 / 63\n",
            "Mixtral: \"Sure, I aim to set SMART goals - Specific, Measurable, Achievable, Relevant, and Time-bound. For instance, I had a goal to improve my data analysis skills last year. I enrolled in an online course, set aside time each week to study and practice, and completed the course within three months. I then applied these skills to my job, which helped me earn a promotion.\"\n",
            "}\n",
            "Analyzing response 45 / 63\n",
            "Mixtral: \"I approach networking as an ongoing process, focusing on building meaningful relationships with people by offering value first. I actively engage in industry events, forums, and webinars, sharing insights and ideas, and asking thoughtful questions. I also make an effort to keep in touch with my contacts through regular, personalized communications, tailoring my messages to their needs and interests. I also use professional networking platforms to connect with like-minded professionals and expand my network. For example, I recently connected with a group of project managers on a professional networking platform, sharing my experience in agile project management. This resulted in gaining\n",
            "Analyzing response 46 / 63\n",
            "Mixtral: \"Sure, I remember a time when my manager provided feedback on my project delivery. They mentioned that I needed to improve my communication during the project, as some team members felt left out of the loop. I took this criticism gracefully and used it as an opportunity to grow. I developed a communication plan for future projects, ensuring regular status updates and encouraging more team engagement. This helped create a more inclusive and collaborative environment, which ultimately led to better project outcomes.\"\n",
            "}\n",
            "Analyzing response 47 / 63\n",
            "Mixtral: \"In my previous internship, I discovered a mistake in a financial report that could have negative impacts on the company. I was torn between reporting the issue, which could make me look bad, or covering it up. I decided to report the mistake to my supervisor, explaining the situation without taking any blame. This helped maintain trust in the team and showed my commitment to integrity.\"\n",
            "}\n",
            "Analyzing response 48 / 63\n",
            "Mixtral: \"In my previous job, I disagreed with my supervisor about the best way to approach a project. I believed that a different method would yield better results, while they were convinced that their way was more efficient. I approached the situation by proposing a compromise: we could try my approach in a small portion of the project as a test, and if it didn't work, we would revert to the original plan. This approach allowed us to see that my method was indeed more effective, and my supervisor agreed to implement it moving forward. This experience showed me the value of open-mindedness and the\n",
            "Analyzing response 49 / 63\n",
            "Mixtral: \"Sure, I remember a time when I received constructive criticism from my supervisor about the pacing of my presentation. They felt it was too rushed and the audience wouldn't be able to follow. I took that feedback positively and made a conscious effort to slow down, pausing after each point to give the audience time to absorb the information. This not only helped improve the flow of my presentation but also allowed me to gauge the audience's understanding better. I am grateful for the constructive criticism as it helped me to become a better presenter.\"\n",
            "}\n",
            "Analyzing response 50 / 63\n",
            "Mixtral: \"For my capstone project in college, I was part of a team responsible for creating a sustainable housing solution. I was in charge of researching and implementing the latest green technologies. I helped the team understand the importance of sustainability in modern housing and how these technologies could positively impact energy consumption. My contributions led to the successful creation of a functional prototype, which was later showcased at a national sustainability conference.\"\n",
            "}\n",
            "Analyzing response 51 / 63\n",
            "Mixtral: \"I begin by identifying the project's needs and objectives, then align them with our team's goals. I break down the project requirements into smaller tasks, prioritizing them by importance and feasibility. This approach ensures each requirement is given adequate attention, and deadlines are met without sacrificing the project's quality.\"\n",
            "}\n",
            "Analyzing response 52 / 63\n",
            "Mixtral: \"For me, success is about growth and learning. I remember a time when I was learning a new language. I set a goal to be able to hold a conversation in that language with a native speaker. I sought out conversation partners, used language learning apps, and even started a small study group. It was challenging, but through consistent effort and learning from my mistakes, I was able to achieve my goal. This experience taught me that success is a journey, not a destination, and that every step taken to learn and grow is a success in itself.\"\n",
            "}\n",
            "Analyzing response 53 / 63\n",
            "Mixtral: \"I remember when I was applying for college, I was torn between two great institutions. One offered an incredible program for my major, while the other was my father's alma mater. I weighed the pros and cons of each, making a list to help visually compare them. I also consulted with friends, family, and mentors. In the end, I chose the college with the best program for my major, and I am grateful I made a methodical and deliberate decision, rather than following my initial emotional response.\"\n",
            "}\n",
            "Analyzing response 54 / 63\n",
            "Mixtral: \"I make sure to establish clear expectations and deadlines at the start. For instance, when I was in a leadership role for a big group project, I ensured everyone knew their responsibilities and by when their tasks were due. This way, everyone knew their part in the project and how it contributed to the overall goal.\"\n",
            "}\n",
            "Analyzing response 55 / 63\n",
            "Mixtral: \"In my previous job, I noticed that our team was spending a lot of time on manual data entry, which was tedious and prone to errors. I took the initiative to research and present a new automation tool to my manager. I demonstrated the time and error reduction benefits, leading to the team adopting the new tool. This proactive move improved our team's efficiency and morale.\"\n",
            "}\n",
            "Analyzing response 56 / 63\n",
            "Mixtral: \"I believe in starting my day with a clear plan of action. I prioritize my tasks and allocate specific time slots for each, allowing flexibility for unexpected tasks. For instance, when I was working on a group project, I dedicated the first hour of every day to complete a section of the project. This helped me to focus on quality and meet deadlines. I find that breaking down larger tasks into smaller, manageable chunks helps to maintain a consistent flow of work. I also use digital tools like calendars and planners to keep myself organized and productive.\"\n",
            "}\n",
            "Analyzing response 57 / 63\n",
            "Mixtral: \"In my previous role, I managed several accounts, each requiring continuous interaction and updates. To ensure each project received adequate attention, I created a detailed schedule, allocating specific time slots for each account. This approach allowed me to monitor their progress meticulously, reducing the risk of missing important deadlines or overlooking critical details.\"\n",
            "}\n",
            "Analyzing response 58 / 63\n",
            "Mixtral: \"I believe in treating everyone with respect and dignity, which fosters an inclusive environment. For instance, in a previous volunteer role, I ensured everyone had a chance to voice their opinions and ideas during discussions. In meetings, I would specifically ask for the opinions of quieter members to make sure everyone felt heard. I also made a point to learn about my team members' diverse backgrounds and experiences to better understand and appreciate them. This approach created a space where everyone felt valued and comfortable contributing, leading to a more productive and inclusive team.\"\n",
            "}\n",
            "Analyzing response 59 / 63\n",
            "Mixtral: \"In a school project, I took the role of a project manager. I used my time management and communication skills to delegate tasks effectively and ensure everyone understood their responsibilities. I created a conducive environment for team members to share their ideas and provided constructive feedback. Ultimately, our team produced an exceptional project that exceeded expectations, and we received a high evaluation from our professor.\"\n",
            "}\n",
            "Analyzing response 60 / 63\n",
            "Mixtral: \"At my previous job, I faced an ethical dilemma when a coworker was struggling with their workload, and I was asked to take on some of their tasks. I was not sure whether this would be beneficial for my own performance or if it would be taking unfair advantage of my coworker. I addressed this by discussing the situation with my supervisor, who explained that this was a temporary situation and my coworker had given their consent. We established a clear timeline and goals to ensure that the arrangement was fair and transparent.\"\n",
            "}\n",
            "Analyzing response 61 / 63\n",
            "Mixtral: \"Sure, during a previous performance review, my supervisor provided feedback that I needed to improve my communication skills, particularly when it came to public speaking. At first, I was a bit taken aback, but I appreciated the honesty and decided to take action. I enrolled in a public speaking course at a local community college to learn and practice better communication skills. This helped me gain confidence and improve in my professional interactions.\"\n",
            "}\n",
            "Analyzing response 62 / 63\n",
            "Mixtral: \"Sure, I can provide an example of a complex problem I faced at work and how I approached it. In my previous job as a data analyst, I noticed a significant discrepancy in our financial reports. I started by identifying the problem's source, then I reached out to the relevant departments to understand their processes better. After identifying the issue was with the automated system, I collaborated with our tech team to rectify the error. This approach helped maintain our financial integrity and strengthened interdepartmental relationships.\"\n",
            "}\n",
            "Analyzing response 63 / 63\n",
            "Mixtral: \"I motivate my team by acknowledging their efforts and praising their successes, which encourages them to continue working hard. I also make sure to provide clear and specific feedback, as it helps them understand how they can improve and what they are doing well. This approach was particularly effective during a group project where every member contributed significantly, and we ended up earning one of the highest grades in the class.\"\n",
            "}\n",
            "Results collected. Building dataframe\n",
            "Results saved to /content/drive/MyDrive/SIOP-ML-2024/interview_results_2024-03-14 05:01:32.598314.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TODO\n",
        "Add parsing instructions\n",
        "Remove quotes, '}' and '`' from output"
      ],
      "metadata": {
        "id": "bKzNN8SP9BEG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vn9f1_P49KLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to grab relevant output\n",
        "\n",
        "def extract_FILL_IN_HERE(text):\n",
        "  \"\"\"\n",
        "  Extracts the first word in quotes if it is either \"first\" or \"second\". If it is neither, parses the whole string for the first occurrence of \"first\", \"second\" \"1st\", \"2nd\" or any semantically similar word.\n",
        "\n",
        "  Args:\n",
        "    text: The input text string.\n",
        "\n",
        "  Returns:\n",
        "    The first word in quotes if it is either \"first\" or \"second\", or the first semantically similar word found in the string.\n",
        "  \"\"\"\n",
        "\n",
        "  # Check for first word in quotes\n",
        "  match = re.search(r'^\"(\\w+)\"', text)\n",
        "  if match and match.group(1) in [\"first\", \"second\"]:\n",
        "    return match.group(1)\n",
        "\n",
        "  # Parse the whole string for semantically similar words\n",
        "  for word in [\"first\", \"second\", \"1st\", \"2nd\", \"former\", \"latter\"]:\n",
        "    if word in text:\n",
        "      return word\n",
        "\n",
        "  # No match found\n",
        "  return None\n",
        "\n",
        "# Example usage:\n",
        "text1 = '\"first\" is the best option.'\n",
        "text2 = 'I prefer the second option.'\n",
        "text3 = 'The former choice is more suitable.'\n",
        "\n",
        "print(extract_first_or_second(text1))  # Output: \"first\"\n",
        "print(extract_first_or_second(text2))  # Output: \"second\"\n",
        "print(extract_first_or_second(text3))  # Output: \"former\"\n",
        "\n",
        "text4 = 'Neither option is suitable.'\n",
        "\n",
        "print(extract_first_or_second(text4))  # Output: None\n"
      ],
      "metadata": {
        "id": "6VcGvWHzN7yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IYK8bicSOKzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scratch"
      ],
      "metadata": {
        "id": "n96JkSoD0_Yk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G1HSMQMe0-5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_empathy_number(response):\n",
        "  \"\"\"\n",
        "  Extracts the value of the first number in a text.\n",
        "\n",
        "  Args:\n",
        "    json_string: A string containing a JSON object.\n",
        "\n",
        "  Returns:\n",
        "    The value of the first number, or None if the key is not found.\n",
        "  \"\"\"\n",
        "\n",
        "  match = re.search(r'\"[0-9]\"', response)\n",
        "  if match:\n",
        "      return match.group(1)\n",
        "  else:\n",
        "      return None"
      ],
      "metadata": {
        "id": "GNX6sWTQRBNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['output'] = df['full_text'].apply(extract_empathy_number)"
      ],
      "metadata": {
        "id": "dLVV0uyWXQQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SLVP8Ye7XZHp",
        "outputId": "edf79f63-7d3e-4ad7-e72a-82f03afc682b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   _id empathy                                          full_text output\n",
              "0   95    None  \"1\"\\n}\\n```\\n\\nIn this scenario, the HR profes...      1\n",
              "1  198    None  \"1\"\\n}\\n```\\nExplanation: In this scenario, th...      1\n",
              "2   23    None  \"1\"\\n} \\n# Explanation\\nThis response demonstr...      1\n",
              "3   81    None  \"1\"\\n}\\n```\\n\\n* This response shows perspecti...      1\n",
              "4   97    None  \"1\"\\n}\\n```\\n\\nThe user has shown empathy by a...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57e55597-8bfe-47ee-9df1-83940c5ccac4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>empathy</th>\n",
              "      <th>full_text</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>95</td>\n",
              "      <td>None</td>\n",
              "      <td>\"1\"\\n}\\n```\\n\\nIn this scenario, the HR profes...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>198</td>\n",
              "      <td>None</td>\n",
              "      <td>\"1\"\\n}\\n```\\nExplanation: In this scenario, th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23</td>\n",
              "      <td>None</td>\n",
              "      <td>\"1\"\\n} \\n# Explanation\\nThis response demonstr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>81</td>\n",
              "      <td>None</td>\n",
              "      <td>\"1\"\\n}\\n```\\n\\n* This response shows perspecti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>97</td>\n",
              "      <td>None</td>\n",
              "      <td>\"1\"\\n}\\n```\\n\\nThe user has shown empathy by a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57e55597-8bfe-47ee-9df1-83940c5ccac4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-57e55597-8bfe-47ee-9df1-83940c5ccac4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-57e55597-8bfe-47ee-9df1-83940c5ccac4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3e7f387f-b4fd-4456-910c-cb7683f318f1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3e7f387f-b4fd-4456-910c-cb7683f318f1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3e7f387f-b4fd-4456-910c-cb7683f318f1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "repr_error": "'str' object has no attribute 'empty'"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/drive/MyDrive/SIOP-ML-2024/results_results_2024-02-28 01:32:31.406554_cleaned.csv', index=False)"
      ],
      "metadata": {
        "id": "8sRYZg-lXx5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#results[0]\n",
        "tokenizer.decode(results[0][\"sequences\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C_xM1tXfN6Dy",
        "outputId": "e30f023f-c97b-4dca-9edb-69434aa7672a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> [INST] <s>  [INST] \\nYou are a helpful AI assistant. Job candidates were asked to provide empathetic responses to a difficult workplace situation. Your task is to classify whether empathy was demonstrated or not in each response.\\n\\n\\nHere is a sample of survey responses and whether empathy was demonstrated (1) or not (0).\\n\\nHi Jonathan, I hope this message finds you well. I hear things are going well with the Beta project. That said, Terry mentioned that there were some issues with the reports. From what I understand, they would like them to be more concise and straight to the point, as well as more business focused. I recommend you reach out to Terry so you both could review in detail one of the reports he submits. This should help you help you align to their expectations. Additionally, i\\'d be happy to review the reports before you send them off to Terry and provide my feedback. I know this  project is important to you, so please let me know how this meeting goes and how else I can help. Regards, William --- 1\\nJonathan, I hope you are well - I am very excited that you are part of this development team and really appreciate all the support you give to us; while doing this some comments have arise that can be  opportunity areas to improve your work and get this program ahead.1. The communication between team members is not clear and improvements can be done to this: by this I mean to connect more with other team members before submitting your reports.2. One of the reasons you were chosen is because of your enthusiastic attitude and knowledge, but too much information sometimes can harm the delivery reports that needs to be concise and business oriented. 3.Please forward me your latest report so we can discuss it furthermore when I come back and see what can be improve and we can work from there.4. Please don\\'t be discourage, these are opportunity areas that we can engage and as always keep up the good work. Have a great week. Thanks --- 1\\nJonathan, First I want to thank you for your help with the Beta project.  However,  it has been brought to my attention that perhaps ABC-5 didn\\'t do enough to prepare you for the extra work and I would like to discuss some issues. The nature of these reports requires them to be technical in nature.  Your insights are very valuable and much appreciated but as the old line goes \"please give me just the facts\".  Given the critical nature of the information you are providing I can\\'t stress the importance of concise yet detail factual reports.  I would like to review your reports as a training exercise to help you better meet the team requirements.  Given that there are some major reports coming up in the immediate future, I would like you to review some training options and then present a report for review.  Again your insights are appreciated but we need to make sure we are presenting the end-use with only the information they need to make a sound business decision. I also understand you would like to grow into a leadership position so I would like to discuss how successfully implementing these changes would be beneficial in demonstrating an ability to grow and take on new challenges. --- 0\\nHi Jonathan, How are You doing with the Beta project? It seams You are very exited about the project.There are two topics that I want to point out that I expct to be Your focus on this project.I review the latest report and saw that in addition to a tchnical information that we have agreed to be included in that, there is a lots of commentaries from Your side. It is greeate that You see the opportunities and perspectives on the findings but I ask You to focus on collecting and passing on the technical information according to the agreed template. We can focus on Your ideas separately once the Beta gets to that stage.The second thing I\\'d like you to focus is the organizing the details in the reports. Please work together with Terry on that. As the deadlines for presenting the reports to CEO are quite challenging, they have lost of hints and tricks how to make the report informative and easy to read. I\\'ve have used his experience and competence myself. It is very important that we submit the report on time. Please add me as well to the reciepient list once You send the infotmation to Terry. Good luck! --- 0\\nDear Jonathan, I am writing to find out how things are going on the Beta project. I understand that you are enjoying the role and finding new applications.I have had some feedback from Terry confirming that you are doing well but there are some improvement points that I would like to discuss with you. It has been noted that your contributions are providing real value and they enjoy working with you, however, some of this value is spoiled by a conversational tone and being a bit verbose. In business correspondence it is essential that the facts are clear, concise and distinguishable from opinion, otherwise the message may be lost (regardless of how good it is).There are a number of significant reports required in the coming weeks. Please could you ensure that you confirm with Terry the exact detail and format required for specific reports and communication. He should be able to provide templates and guidance to ensure that his requirements are met. I would also recommend that you undertake a report-writing course, which should help you to ensure that you convey your great ideas in the best possible way.I am keen to support you to ensure the success of the project and your professional development. When I return in 2 weeks I would like to have a conference call with you and Terry to better understand how we can help you going forward.  Please could you respond to confirm that you have received this email. Regards, William --- 0\\n\\nYou must always respond in JSON format containing `\"trait\"` and `\"present\"` key-value pairs. For example, to respond to the prompt, \"Hi Jonathan, I wanted to have  a discussion with you but since you are travelling i am sharing in this mailThis is related to Beta project and reports coming from there.While we are all excited by the passion and enthusiasm you are bringing i wanted to share some early feedback with you. 1.Please try to be concise in reports and mention facts that teams can refer . We love opinions but lets save those for our brainstorming discussions. 2.For Business writing as you are getting started to help you set up for success we are nominating you for a training program so that your reports are way more effective. I hope as you set on your growth journey and take larger roles a superb feedback from your peers and stakeholders will help. I truly believe above two points can really help you take you there. Wishing you all the best and do share in case you have feedback or inputs from your side. Regards William\" you must use the calculator tool like so:\\n\\n```json\\n{\\n    \"trait\": \"empathy\",\\n    \"present\": \"0\"\\n}\\n```\\n\\nOr to answer the prompt \"Hi Jonathan, I hope you\\'re having safe travels along your way. I\\'m reaching out to you because you are a valued employee, and we appreciate your hard work and research. While I understand you are passionate about these projects, it is imperative that you keep your reports concise, seeing as we are all continuously on a time crunch. Because these reports are not written as efficiently as possible, it is taking too much of our time to read and determine which bit of information is most valuable. I need you to shift the way you are writing these reports so that way we can maximize our work flow processes. We love having you on our team, but if you can not make these necessary changes, we may have to relocate your skill set to a different department. However, I am positive you can make these minor changes in the way you create your reports. Please research the formal way to write reports so that way you no longer add too much information. These reports should have less opinions, and more facts. I will also send some material for you to review on how to keep these reports business friendly. I love your passion and your drive, I am hoping we can continue to have you on this project. A few minor changes will be all it takes to get the ball rolling in the right direction! If you have any concerns, feel free to reach out to me and I will be more than happy to assist. Thank you, William\" you must respond:\\n\\n```json\\n{\\n    \"trait\": \"empathy\",\\n    \"present\": \"1\"\\n}\\n```\\n\\nRemember, even when answering to the user, you must still use this JSON format! If you\\'d like to ask how the user is doing you must write:\\n\\n```json\\n{\\n    \"trait\": \"empathy\",\\n    \"present\": \"How are you today?\"\\n}\\n```\\n\\nLet\\'s get started. The response prompt is as follows.\\n [/INST]\\nUser: Hi Jonathan, I wanted to reach out to thank you for all of your work on the Beta project! It sounds like you are working well with the team and doing a great job of identifying some needed improvements! Today, I would like to discuss your reports. I\\'ve looked over the last few and identified a couple of areas of improvement, specifically around the extra commentary that was included and the accuracy/organization. The Beta project is extremely important and if it fails, many of us could lose our jobs. For that reason, I would like for you to collaborate with Terry when creating your reports so that we can ensure that they are in line with what is expected. I know that this is a new project for you and I\\'m sure you are excited, but also a little overwhelmed. Terry will help support you through this learning curve and you will be up to speed in no time. Can you give me your commitment that you will work through this with him? Thank you for your support, William\\nAssistant: ```json\\n{\\n\"trait\":  [/INST] \"empathy\",\\n\"present\": \"1\"\\n}\\n\\nThe assistant recognizes that the user is demonstrating empathy towards Jonathan by acknowledging his efforts, identifying areas for improvement in a constructive manner, and offering support in the form of a mentor to help him improve. This shows understanding and consideration for Jonathan\\'s learning curve and the importance of the project\\'s success.</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def format_output(text: str):\n",
        "    full_json_str = '{\\n\"trait\": '+text\n",
        "    full_json_str = full_json_str.strip()\n",
        "    if full_json_str.endswith(\"```\"):\n",
        "        full_json_str = full_json_str[:-3]\n",
        "    return json.loads(full_json_str)"
      ],
      "metadata": {
        "id": "npJG1PKjFgCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_template_head = \"\"\"\n",
        "You are a helpful AI assistant. Job candidates were asked to provide empathetic responses to a difficult workplace situation. Your task is to classify whether empathy was demonstrated or not in each response.\n",
        "\n",
        "\n",
        "Here is a sample of survey responses and whether empathy was demonstrated (1) or not (0). The correct answer is provided after the `---` following each prompt.\n",
        "\n",
        "Hi Jonathan, I hope this message finds you well. I hear things are going well with the Beta project. That said, Terry mentioned that there were some issues with the reports. From what I understand, they would like them to be more concise and straight to the point, as well as more business focused. I recommend you reach out to Terry so you both could review in detail one of the reports he submits. This should help you help you align to their expectations. Additionally, i'd be happy to review the reports before you send them off to Terry and provide my feedback. I know this  project is important to you, so please let me know how this meeting goes and how else I can help. Regards, William --- \"1\"\n",
        "Jonathan, I hope you are well - I am very excited that you are part of this development team and really appreciate all the support you give to us; while doing this some comments have arise that can be  opportunity areas to improve your work and get this program ahead.1. The communication between team members is not clear and improvements can be done to this: by this I mean to connect more with other team members before submitting your reports.2. One of the reasons you were chosen is because of your enthusiastic attitude and knowledge, but too much information sometimes can harm the delivery reports that needs to be concise and business oriented. 3.Please forward me your latest report so we can discuss it furthermore when I come back and see what can be improve and we can work from there.4. Please don't be discourage, these are opportunity areas that we can engage and as always keep up the good work. Have a great week. Thanks --- \"1\"\n",
        "Jonathan, First I want to thank you for your help with the Beta project.  However,  it has been brought to my attention that perhaps ABC-5 didn't do enough to prepare you for the extra work and I would like to discuss some issues. The nature of these reports requires them to be technical in nature.  Your insights are very valuable and much appreciated but as the old line goes \"please give me just the facts\".  Given the critical nature of the information you are providing I can't stress the importance of concise yet detail factual reports.  I would like to review your reports as a training exercise to help you better meet the team requirements.  Given that there are some major reports coming up in the immediate future, I would like you to review some training options and then present a report for review.  Again your insights are appreciated but we need to make sure we are presenting the end-use with only the information they need to make a sound business decision. I also understand you would like to grow into a leadership position so I would like to discuss how successfully implementing these changes would be beneficial in demonstrating an ability to grow and take on new challenges. --- \"0\"\n",
        "Hi Jonathan, How are You doing with the Beta project? It seams You are very exited about the project.There are two topics that I want to point out that I expct to be Your focus on this project.I review the latest report and saw that in addition to a tchnical information that we have agreed to be included in that, there is a lots of commentaries from Your side. It is greeate that You see the opportunities and perspectives on the findings but I ask You to focus on collecting and passing on the technical information according to the agreed template. We can focus on Your ideas separately once the Beta gets to that stage.The second thing I'd like you to focus is the organizing the details in the reports. Please work together with Terry on that. As the deadlines for presenting the reports to CEO are quite challenging, they have lost of hints and tricks how to make the report informative and easy to read. I've have used his experience and competence myself. It is very important that we submit the report on time. Please add me as well to the reciepient list once You send the infotmation to Terry. Good luck! --- \"0\"\n",
        "Dear Jonathan, I am writing to find out how things are going on the Beta project. I understand that you are enjoying the role and finding new applications.I have had some feedback from Terry confirming that you are doing well but there are some improvement points that I would like to discuss with you. It has been noted that your contributions are providing real value and they enjoy working with you, however, some of this value is spoiled by a conversational tone and being a bit verbose. In business correspondence it is essential that the facts are clear, concise and distinguishable from opinion, otherwise the message may be lost (regardless of how good it is).There are a number of significant reports required in the coming weeks. Please could you ensure that you confirm with Terry the exact detail and format required for specific reports and communication. He should be able to provide templates and guidance to ensure that his requirements are met. I would also recommend that you undertake a report-writing course, which should help you to ensure that you convey your great ideas in the best possible way.I am keen to support you to ensure the success of the project and your professional development. When I return in 2 weeks I would like to have a conference call with you and Terry to better understand how we can help you going forward.  Please could you respond to confirm that you have received this email. Regards, William --- \"0\"\n",
        "\n",
        "You must always respond in JSON format containing `\"trait\"` and `\"present\"` key-value pairs. For example, to respond to the prompt, \"Hi Jonathan, I wanted to have  a discussion with you but since you are travelling i am sharing in this mailThis is related to Beta project and reports coming from there.While we are all excited by the passion and enthusiasm you are bringing i wanted to share some early feedback with you. 1.Please try to be concise in reports and mention facts that teams can refer . We love opinions but lets save those for our brainstorming discussions. 2.For Business writing as you are getting started to help you set up for success we are nominating you for a training program so that your reports are way more effective. I hope as you set on your growth journey and take larger roles a superb feedback from your peers and stakeholders will help. I truly believe above two points can really help you take you there. Wishing you all the best and do share in case you have feedback or inputs from your side. Regards William\" you must use the calculator tool like so:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"trait\": \"empathy\",\n",
        "    \"present\": \"0\"\n",
        "}\n",
        "```\n",
        "\n",
        "Or to answer the prompt \"Hi Jonathan, I hope you're having safe travels along your way. I'm reaching out to you because you are a valued employee, and we appreciate your hard work and research. While I understand you are passionate about these projects, it is imperative that you keep your reports concise, seeing as we are all continuously on a time crunch. Because these reports are not written as efficiently as possible, it is taking too much of our time to read and determine which bit of information is most valuable. I need you to shift the way you are writing these reports so that way we can maximize our work flow processes. We love having you on our team, but if you can not make these necessary changes, we may have to relocate your skill set to a different department. However, I am positive you can make these minor changes in the way you create your reports. Please research the formal way to write reports so that way you no longer add too much information. These reports should have less opinions, and more facts. I will also send some material for you to review on how to keep these reports business friendly. I love your passion and your drive, I am hoping we can continue to have you on this project. A few minor changes will be all it takes to get the ball rolling in the right direction! If you have any concerns, feel free to reach out to me and I will be more than happy to assist. Thank you, William\" you must respond:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"trait\": \"empathy\",\n",
        "    \"present\": \"1\"\n",
        "}\n",
        "```\n",
        "\n",
        "Remember, even when answering to the user, you must still use this JSON format! If you'd like to ask how the user is doing you must write:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"trait\": \"empathy\",\n",
        "    \"present\": \"How are you today?\"\n",
        "}\n",
        "```\n",
        "\n",
        "Let's get started. The response prompt is as follows.\n",
        "\n",
        "User: \"\"\"\n",
        "\n",
        "agent_template_tail = \"\"\"\n",
        "\n",
        "Assistant: ```json\n",
        "{\n",
        "    \"trait\": \"\"\"\n"
      ],
      "metadata": {
        "id": "jcmKxPZBXKH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a function that scans a text input for the sequence \"[/INST] \" and returns only the portion that comes after that\n",
        "\n",
        "def extract_after_inst(text):\n",
        "  \"\"\"\n",
        "  Extracts the portion of text that comes after the sequence \"[/INST] \".\n",
        "\n",
        "  Args:\n",
        "    text: The input text string.\n",
        "\n",
        "  Returns:\n",
        "    The portion of text after \"[/INST] \", or None if the sequence is not found.\n",
        "  \"\"\"\n",
        "\n",
        "  index = text.find(\"[/INST] \")\n",
        "  if index != -1:\n",
        "    return text[index + len(\"[/INST] \"):]\n",
        "  else:\n",
        "    return None\n",
        "\n",
        "# Example usage:\n",
        "text = \"This is some text before [/INST] and this is some text after.\"\n",
        "extracted_text = extract_after_inst(text)\n",
        "print(extracted_text)  # Output: \"and this is some text after.\"\n",
        "\n",
        "text = \"This text does not contain the sequence.\"\n",
        "extracted_text = extract_after_inst(text)\n",
        "print(extracted_text)  # Output: None\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9-0ALmcQ-s0",
        "outputId": "181fedcb-fded-4e1d-d16e-c4755cde9a58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "and this is some text after.\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extract_present_value(extract_after_inst(tokenizer.decode(results[0][\"sequences\"][0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iBZKt4YORSsB",
        "outputId": "618ec822-d35b-4f72-99f5-447c60ecd344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run the model"
      ],
      "metadata": {
        "id": "Z4hBFYtPTUzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_template = \"\"\"\n",
        "You are a helpful AI assistant. Job candidates were asked to provide empathetic responses to a difficult workplace situation. Your task is to classify whether empathy was demonstrated or not in each response.\n",
        "\n",
        "\n",
        "Here is a sample of survey responses and whether empathy was demonstrated (1) or not (0).\n",
        "\n",
        "Hi Jonathan, I hope this message finds you well. I hear things are going well with the Beta project. That said, Terry mentioned that there were some issues with the reports. From what I understand, they would like them to be more concise and straight to the point, as well as more business focused. I recommend you reach out to Terry so you both could review in detail one of the reports he submits. This should help you help you align to their expectations. Additionally, i'd be happy to review the reports before you send them off to Terry and provide my feedback. I know this  project is important to you, so please let me know how this meeting goes and how else I can help. Regards, William --- 1\n",
        "Jonathan, I hope you are well - I am very excited that you are part of this development team and really appreciate all the support you give to us; while doing this some comments have arise that can be  opportunity areas to improve your work and get this program ahead.1. The communication between team members is not clear and improvements can be done to this: by this I mean to connect more with other team members before submitting your reports.2. One of the reasons you were chosen is because of your enthusiastic attitude and knowledge, but too much information sometimes can harm the delivery reports that needs to be concise and business oriented. 3.Please forward me your latest report so we can discuss it furthermore when I come back and see what can be improve and we can work from there.4. Please don't be discourage, these are opportunity areas that we can engage and as always keep up the good work. Have a great week. Thanks --- 1\n",
        "Hi Jonathan, Good to hear you are enjoying the work. I would like to discuss with you feedback on your assignment and the reports you are producing. It is very important to understand the stakeholders who will be reading your report. You may have gathered a lot of good information BUT do not put them all on your reports. The report should state facts and not your opinions. Create reports for the purpose and for the audience. I would also suggest that you reach out to Terry to understand what information is needed on the reports you produce.Having said that, the additional insights you gathered are very important too. Please add them to our knowledge repository and share with the team. It will be a great sharing and learning experience. You are very valuable in your knowledge and I think that it would benefit you and the organization tremendously when you are to channelize your insights and present the facts well. I would encourage you to enroll for the business writing training course. Please choose a date from the learning calendar and let me know. Regards, William --- 1\n",
        "Jonathan, First I want to thank you for your help with the Beta project.  However,  it has been brought to my attention that perhaps ABC-5 didn't do enough to prepare you for the extra work and I would like to discuss some issues. The nature of these reports requires them to be technical in nature.  Your insights are very valuable and much appreciated but as the old line goes \"please give me just the facts\".  Given the critical nature of the information you are providing I can't stress the importance of concise yet detail factual reports.  I would like to review your reports as a training exercise to help you better meet the team requirements.  Given that there are some major reports coming up in the immediate future, I would like you to review some training options and then present a report for review.  Again your insights are appreciated but we need to make sure we are presenting the end-use with only the information they need to make a sound business decision. I also understand you would like to grow into a leadership position so I would like to discuss how successfully implementing these changes would be beneficial in demonstrating an ability to grow and take on new challenges. --- 0\n",
        "Hey Jonathan! I've been in touch with Terry, I'm so glad to hear how much you are enjoying the Beta Project, I even hear you are hoping that this experience will further your ambitions toward a Lead Engineer position! However, I understand there has been some issues with your reports that Terry has brought up with you, and I wanted to take a few minutes to discuss them.1) Opinion vs. FactsYour reports contain a lot of insights about what the data means, and at times finding the specific hard facts can be difficult.2) Level of DetailYou include every bit of data that you can into your reports, which can make it difficult to take away the larger picture.I want to encourage you to take these things away for the following reasons:1) your reports are reviewed by everyone in upper management, including the CEO! The opinions you have are great, but when evaluating documents the CEO just needs to highest level, most important items. The nitty-gritty would fall to another department2) as you have a desire to move up and be a Lead Engineer, these kinds of reports will be more and more common. Keeping your thoughts organized and well documented is going to become a very important skill to have.For your next report I would like you to prepare a cover sheet that goes with the report. This cover sheet should be a single page highlighting only the key facts of the report. Your own opinions and analysis can be included, but let those who are interested read it on their own time, the high level facts are key for the meeting they will be presented in. I would also encourage you to make sure the rest of the report has clearly defined headings and topics, so it is easy to find information related to each item. I --- 1\n",
        "Hi Jonathan, How are You doing with the Beta project? It seams You are very exited about the project.There are two topics that I want to point out that I expct to be Your focus on this project.I review the latest report and saw that in addition to a tchnical information that we have agreed to be included in that, there is a lots of commentaries from Your side. It is greeate that You see the opportunities and perspectives on the findings but I ask You to focus on collecting and passing on the technical information according to the agreed template. We can focus on Your ideas separately once the Beta gets to that stage.The second thing I'd like you to focus is the organizing the details in the reports. Please work together with Terry on that. As the deadlines for presenting the reports to CEO are quite challenging, they have lost of hints and tricks how to make the report informative and easy to read. I've have used his experience and competence myself. It is very important that we submit the report on time. Please add me as well to the reciepient list once You send the infotmation to Terry. Good luck! --- 0\n",
        "\n",
        "\n",
        "You must always respond in JSON format containing `\"trait\"` and `\"present\"` key-value pairs. For example, to respond to the prompt, \"Hi Jonathan, I wanted to have  a discussion with you but since you are travelling i am sharing in this mailThis is related to Beta project and reports coming from there.While we are all excited by the passion and enthusiasm you are bringing i wanted to share some early feedback with you. 1.Please try to be concise in reports and mention facts that teams can refer . We love opinions but lets save those for our brainstorming discussions. 2.For Business writing as you are getting started to help you set up for success we are nominating you for a training program so that your reports are way more effective. I hope as you set on your growth journey and take larger roles a superb feedback from your peers and stakeholders will help. I truly believe above two points can really help you take you there. Wishing you all the best and do share in case you have feedback or inputs from your side. Regards William\" you must use the calculator tool like so:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"trait\": \"empathy\",\n",
        "    \"present\": \"0\"\n",
        "}\n",
        "```\n",
        "\n",
        "Or to answer the prompt \"Hi Jonathan, I hope you're having safe travels along your way. I'm reaching out to you because you are a valued employee, and we appreciate your hard work and research. While I understand you are passionate about these projects, it is imperative that you keep your reports concise, seeing as we are all continuously on a time crunch. Because these reports are not written as efficiently as possible, it is taking too much of our time to read and determine which bit of information is most valuable. I need you to shift the way you are writing these reports so that way we can maximize our work flow processes. We love having you on our team, but if you can not make these necessary changes, we may have to relocate your skill set to a different department. However, I am positive you can make these minor changes in the way you create your reports. Please research the formal way to write reports so that way you no longer add too much information. These reports should have less opinions, and more facts. I will also send some material for you to review on how to keep these reports business friendly. I love your passion and your drive, I am hoping we can continue to have you on this project. A few minor changes will be all it takes to get the ball rolling in the right direction! If you have any concerns, feel free to reach out to me and I will be more than happy to assist. Thank you, William\" you must respond:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"trait\": \"empathy\",\n",
        "    \"present\": \"1\"\n",
        "}\n",
        "```\n",
        "\n",
        "Remember, even when answering to the user, you must still use this JSON format! If you'd like to ask how the user is doing you must write:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"trait\": \"empathy\",\n",
        "    \"present\": \"How are you today?\"\n",
        "}\n",
        "```\n",
        "\n",
        "Let's get started. The response prompt is as follows.\n",
        "\n",
        "User: Hello, Jonathan....i understand you are pretty excited about the Beta project and all its possibilities. You have a key role in that project and the information you provide is critical for seniors to make decisions.In order for the process to flow more smoothly I need you to focus and limit your report to data and technical information. Recommendations and opinions could be sent to me on a weekely basis. Also, I would like to sit down and coach you on report writing when I am back. That will be a great development for your career. In the meantime, please let me knwo if it would be helpeful to do that with\n",
        "\n",
        "Assistant: ```json\n",
        "{\n",
        "    \"trait\": \"\"\""
      ],
      "metadata": {
        "id": "sf3uu1ajuJn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Next up\n",
        "\n",
        "Will want to turn the above into a function so that I can apply it better, output the results (refer to example below for inspiration)\n",
        "\n",
        "Prompt engineering! The current prompt seems only to return 1 (empathetic)\n",
        "-also it is long and not super efficient. Probably can remove the \"trait\" json aspect.\n",
        "-also also need to extract the predicted value from the response and save it to a df for exporting to csv"
      ],
      "metadata": {
        "id": "fE6ePasPXljF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUrfQ04wbVe6"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import requests\n",
        "from transformers import pipeline\n",
        "\n",
        "def determine_empathy(text: str) -> int:\n",
        "    \"\"\"\n",
        "    Determines whether the respondent demonstrates empathy using the Mixtral model.\n",
        "\n",
        "    Args:\n",
        "    text (str): The text to analyze.\n",
        "\n",
        "    Returns:\n",
        "    int: 1 if empathy is demonstrated, 0 otherwise.\n",
        "    \"\"\"\n",
        "    headers = {\"Authorization\": f\"Bearer {hf_api_token}\"}\n",
        "    API_URL = \"https://api-inference.huggingface.co/models/YOUR_MODEL_NAME\"  # Replace YOUR_MODEL_NAME with the actual model name\n",
        "    payload = {\"inputs\": text}\n",
        "\n",
        "    response = requests.post(API_URL, headers=headers, json=payload)\n",
        "    result = response.json()\n",
        "\n",
        "    # Depending on the output of your model, adjust the following lines accordingly\n",
        "    # This is a placeholder for how you might interpret the model's response\n",
        "    # You may need to adjust the logic based on the model's specific output format\n",
        "    empathy_score = 1 if 'empathetic' in result['label'] else 0  # Adjust based on actual output\n",
        "    return empathy_score\n",
        "\n",
        "def process_csv(input_file: str, output_file: str):\n",
        "    \"\"\"\n",
        "    Processes the input CSV to add an empathy analysis and outputs a new CSV.\n",
        "\n",
        "    Args:\n",
        "    input_file (str): Path to the input CSV file.\n",
        "    output_file (str): Path to the output CSV file.\n",
        "    \"\"\"\n",
        "    processed_data = []\n",
        "\n",
        "    with open(input_file, mode='r', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        for row in reader:\n",
        "            empathy_score = determine_empathy(row['text'])\n",
        "            processed_data.append((row['responseid'], row['text'], empathy_score))\n",
        "\n",
        "    with open(output_file, mode='w', encoding='utf-8', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(['responseid', 'text', 'empathy'])\n",
        "        writer.writerows(processed_data)\n",
        "\n",
        "# Example usage\n",
        "input_csv = 'path/to/your/input.csv'\n",
        "output_csv = 'path/to/your/output.csv'\n",
        "process_csv(input_csv, output_csv)\n"
      ]
    }
  ]
}